{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import scipy.stats as ss\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import imgkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>user_id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>original_tweet</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006-09-10 11:07:07</td>\n",
       "      <td>trying to figure out what this thing is</td>\n",
       "      <td>5622.0</td>\n",
       "      <td>39.1413</td>\n",
       "      <td>-84.506</td>\n",
       "      <td>NaN</td>\n",
       "      <td>trying to figure out what this thing is.</td>\n",
       "      <td>4.154872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-03-17 09:59:46</td>\n",
       "      <td>killing my land line</td>\n",
       "      <td>5622.0</td>\n",
       "      <td>39.1413</td>\n",
       "      <td>-84.506</td>\n",
       "      <td>NaN</td>\n",
       "      <td>killing my land line.</td>\n",
       "      <td>4.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-03-18 11:48:24</td>\n",
       "      <td>my expense report</td>\n",
       "      <td>5622.0</td>\n",
       "      <td>39.1413</td>\n",
       "      <td>-84.506</td>\n",
       "      <td>NaN</td>\n",
       "      <td>my expense report</td>\n",
       "      <td>4.275294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-03-21 12:20:05</td>\n",
       "      <td>putting down the llama book</td>\n",
       "      <td>5622.0</td>\n",
       "      <td>39.1413</td>\n",
       "      <td>-84.506</td>\n",
       "      <td>NaN</td>\n",
       "      <td>putting down the llama book.</td>\n",
       "      <td>4.258095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2007-04-23 16:33:41</td>\n",
       "      <td>releasing final art</td>\n",
       "      <td>5622.0</td>\n",
       "      <td>39.1413</td>\n",
       "      <td>-84.506</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Releasing Final Art.</td>\n",
       "      <td>4.528889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date                                    tweet  user_id  \\\n",
       "0  2006-09-10 11:07:07  trying to figure out what this thing is   5622.0   \n",
       "1  2007-03-17 09:59:46                     killing my land line   5622.0   \n",
       "2  2007-03-18 11:48:24                        my expense report   5622.0   \n",
       "3  2007-03-21 12:20:05              putting down the llama book   5622.0   \n",
       "5  2007-04-23 16:33:41                      releasing final art   5622.0   \n",
       "\n",
       "   latitude  longitude hashtags                            original_tweet  \\\n",
       "0   39.1413    -84.506      NaN  trying to figure out what this thing is.   \n",
       "1   39.1413    -84.506      NaN                     killing my land line.   \n",
       "2   39.1413    -84.506      NaN                         my expense report   \n",
       "3   39.1413    -84.506      NaN              putting down the llama book.   \n",
       "5   39.1413    -84.506      NaN                      Releasing Final Art.   \n",
       "\n",
       "      score  \n",
       "0  4.154872  \n",
       "1  4.375000  \n",
       "2  4.275294  \n",
       "3  4.258095  \n",
       "5  4.528889  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting DF\n",
    "tweetsdf = pd.read_csv('../data/finalScores.csv').dropna(subset=['score'])\n",
    "tweetsdf = tweetsdf.iloc[:,2:]\n",
    "tweetsdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>user_id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>original_tweet</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>2009-10-24 19:53:09</td>\n",
       "      <td>school of cock</td>\n",
       "      <td>753393.0</td>\n",
       "      <td>34.11410</td>\n",
       "      <td>-118.4068</td>\n",
       "      <td>oneletteroffmovies</td>\n",
       "      <td>@SarahKSilverman School of Cock #oneletteroffm...</td>\n",
       "      <td>4.192857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>2007-03-23 01:56:29</td>\n",
       "      <td>bomb this wont happen again i promise</td>\n",
       "      <td>1983121.0</td>\n",
       "      <td>45.31090</td>\n",
       "      <td>-122.7702</td>\n",
       "      <td>1</td>\n",
       "      <td>Bomb #1, This wont happen again, I promise!</td>\n",
       "      <td>4.245946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>2007-03-23 01:56:30</td>\n",
       "      <td>bomb this wont happen again i promise</td>\n",
       "      <td>1983121.0</td>\n",
       "      <td>45.31090</td>\n",
       "      <td>-122.7702</td>\n",
       "      <td>2</td>\n",
       "      <td>Bomb #2, This wont happen again, I promise!</td>\n",
       "      <td>4.245946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>2009-05-13 13:38:06</td>\n",
       "      <td>im sure im late with this but here you go</td>\n",
       "      <td>1925401.0</td>\n",
       "      <td>42.38890</td>\n",
       "      <td>-71.2423</td>\n",
       "      <td>imw051309</td>\n",
       "      <td>@gregorysimpson i'm sure i'm late with this bu...</td>\n",
       "      <td>3.956098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>2009-06-20 09:45:55</td>\n",
       "      <td>i also want to send support to everyone in ira...</td>\n",
       "      <td>1925401.0</td>\n",
       "      <td>42.38890</td>\n",
       "      <td>-71.2423</td>\n",
       "      <td>teaparty</td>\n",
       "      <td>@jillwhalen i also want to send support to eve...</td>\n",
       "      <td>4.078384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8681398</th>\n",
       "      <td>2010-03-16 12:17:28</td>\n",
       "      <td>trt shay was whoopin dat assstop lyin lol</td>\n",
       "      <td>58669408.0</td>\n",
       "      <td>43.02179</td>\n",
       "      <td>-83.6757</td>\n",
       "      <td>whenifirstmet</td>\n",
       "      <td>TRT @kyekye22: #whenifirstmet @DineroMEECH Sha...</td>\n",
       "      <td>4.132727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8681399</th>\n",
       "      <td>2010-03-16 12:17:51</td>\n",
       "      <td>rt he blew the games for us at this tournament...</td>\n",
       "      <td>58669408.0</td>\n",
       "      <td>43.02179</td>\n",
       "      <td>-83.6757</td>\n",
       "      <td>wheniirstmet</td>\n",
       "      <td>RT @smittylu: #wheniirstmet @DineroMEECH he bl...</td>\n",
       "      <td>3.944815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8681415</th>\n",
       "      <td>2010-03-16 12:58:33</td>\n",
       "      <td>just saw measurements  that is  i need  see th...</td>\n",
       "      <td>58669408.0</td>\n",
       "      <td>43.02179</td>\n",
       "      <td>-83.6757</td>\n",
       "      <td>unreal</td>\n",
       "      <td>Just saw @cherokeedassxxx measurements: 36-29-...</td>\n",
       "      <td>4.091636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8681423</th>\n",
       "      <td>2010-03-16 13:19:24</td>\n",
       "      <td>rtdineromeech it was at my hotel partyi though...</td>\n",
       "      <td>58669408.0</td>\n",
       "      <td>43.02179</td>\n",
       "      <td>-83.6757</td>\n",
       "      <td>whenifirstmet,nolie</td>\n",
       "      <td>RT @CharmaineBryant: #WhenIFirstMet--&gt;&gt;@Dinero...</td>\n",
       "      <td>3.905769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8681435</th>\n",
       "      <td>2010-03-16 20:03:37</td>\n",
       "      <td>rt he was  talking very loudly for no reason l...</td>\n",
       "      <td>58669408.0</td>\n",
       "      <td>43.02179</td>\n",
       "      <td>-83.6757</td>\n",
       "      <td>whenifirstmet</td>\n",
       "      <td>RT @Miyoko92: #whenifirstmet @DineroMEECH he w...</td>\n",
       "      <td>3.897447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>783446 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        date  \\\n",
       "94       2009-10-24 19:53:09   \n",
       "315      2007-03-23 01:56:29   \n",
       "317      2007-03-23 01:56:30   \n",
       "355      2009-05-13 13:38:06   \n",
       "363      2009-06-20 09:45:55   \n",
       "...                      ...   \n",
       "8681398  2010-03-16 12:17:28   \n",
       "8681399  2010-03-16 12:17:51   \n",
       "8681415  2010-03-16 12:58:33   \n",
       "8681423  2010-03-16 13:19:24   \n",
       "8681435  2010-03-16 20:03:37   \n",
       "\n",
       "                                                     tweet     user_id  \\\n",
       "94                                          school of cock    753393.0   \n",
       "315                  bomb this wont happen again i promise   1983121.0   \n",
       "317                  bomb this wont happen again i promise   1983121.0   \n",
       "355              im sure im late with this but here you go   1925401.0   \n",
       "363      i also want to send support to everyone in ira...   1925401.0   \n",
       "...                                                    ...         ...   \n",
       "8681398          trt shay was whoopin dat assstop lyin lol  58669408.0   \n",
       "8681399  rt he blew the games for us at this tournament...  58669408.0   \n",
       "8681415  just saw measurements  that is  i need  see th...  58669408.0   \n",
       "8681423  rtdineromeech it was at my hotel partyi though...  58669408.0   \n",
       "8681435  rt he was  talking very loudly for no reason l...  58669408.0   \n",
       "\n",
       "         latitude  longitude             hashtags  \\\n",
       "94       34.11410  -118.4068   oneletteroffmovies   \n",
       "315      45.31090  -122.7702                    1   \n",
       "317      45.31090  -122.7702                    2   \n",
       "355      42.38890   -71.2423            imw051309   \n",
       "363      42.38890   -71.2423             teaparty   \n",
       "...           ...        ...                  ...   \n",
       "8681398  43.02179   -83.6757        whenifirstmet   \n",
       "8681399  43.02179   -83.6757         wheniirstmet   \n",
       "8681415  43.02179   -83.6757               unreal   \n",
       "8681423  43.02179   -83.6757  whenifirstmet,nolie   \n",
       "8681435  43.02179   -83.6757        whenifirstmet   \n",
       "\n",
       "                                            original_tweet     score  \n",
       "94       @SarahKSilverman School of Cock #oneletteroffm...  4.192857  \n",
       "315            Bomb #1, This wont happen again, I promise!  4.245946  \n",
       "317            Bomb #2, This wont happen again, I promise!  4.245946  \n",
       "355      @gregorysimpson i'm sure i'm late with this bu...  3.956098  \n",
       "363      @jillwhalen i also want to send support to eve...  4.078384  \n",
       "...                                                    ...       ...  \n",
       "8681398  TRT @kyekye22: #whenifirstmet @DineroMEECH Sha...  4.132727  \n",
       "8681399  RT @smittylu: #wheniirstmet @DineroMEECH he bl...  3.944815  \n",
       "8681415  Just saw @cherokeedassxxx measurements: 36-29-...  4.091636  \n",
       "8681423  RT @CharmaineBryant: #WhenIFirstMet-->>@Dinero...  3.905769  \n",
       "8681435  RT @Miyoko92: #whenifirstmet @DineroMEECH he w...  3.897447  \n",
       "\n",
       "[783446 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetsdf.dropna(subset=['hashtags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/matplotlib/category.py:189\u001b[0m, in \u001b[0;36mUnitData._str_is_convertible\u001b[0;34m(val)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 189\u001b[0m     \u001b[39mfloat\u001b[39m(val)\n\u001b[1;32m    190\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '2010-02-14 11:20:08'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plt\u001b[39m.\u001b[39;49mhist(tweetsdf\u001b[39m.\u001b[39;49mdropna(subset\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mhashtags\u001b[39;49m\u001b[39m'\u001b[39;49m])[\u001b[39m'\u001b[39;49m\u001b[39mdate\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m      2\u001b[0m plt\u001b[39m.\u001b[39mxticks(rotation\u001b[39m=\u001b[39m\u001b[39m45\u001b[39m)\n\u001b[1;32m      3\u001b[0m plt\u001b[39m.\u001b[39mxlim(pd\u001b[39m.\u001b[39mTimestamp(\u001b[39m'\u001b[39m\u001b[39m2009-01-01\u001b[39m\u001b[39m'\u001b[39m), pd\u001b[39m.\u001b[39mTimestamp(\u001b[39m'\u001b[39m\u001b[39m2010-07-31\u001b[39m\u001b[39m'\u001b[39m))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/matplotlib/pyplot.py:2645\u001b[0m, in \u001b[0;36mhist\u001b[0;34m(x, bins, range, density, weights, cumulative, bottom, histtype, align, orientation, rwidth, log, color, label, stacked, data, **kwargs)\u001b[0m\n\u001b[1;32m   2639\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[39m.\u001b[39mhist)\n\u001b[1;32m   2640\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhist\u001b[39m(\n\u001b[1;32m   2641\u001b[0m         x, bins\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39mrange\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, density\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, weights\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   2642\u001b[0m         cumulative\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, bottom\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, histtype\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbar\u001b[39m\u001b[39m'\u001b[39m, align\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmid\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   2643\u001b[0m         orientation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mvertical\u001b[39m\u001b[39m'\u001b[39m, rwidth\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, log\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, color\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   2644\u001b[0m         label\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, stacked\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m-> 2645\u001b[0m     \u001b[39mreturn\u001b[39;00m gca()\u001b[39m.\u001b[39;49mhist(\n\u001b[1;32m   2646\u001b[0m         x, bins\u001b[39m=\u001b[39;49mbins, \u001b[39mrange\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mrange\u001b[39;49m, density\u001b[39m=\u001b[39;49mdensity, weights\u001b[39m=\u001b[39;49mweights,\n\u001b[1;32m   2647\u001b[0m         cumulative\u001b[39m=\u001b[39;49mcumulative, bottom\u001b[39m=\u001b[39;49mbottom, histtype\u001b[39m=\u001b[39;49mhisttype,\n\u001b[1;32m   2648\u001b[0m         align\u001b[39m=\u001b[39;49malign, orientation\u001b[39m=\u001b[39;49morientation, rwidth\u001b[39m=\u001b[39;49mrwidth, log\u001b[39m=\u001b[39;49mlog,\n\u001b[1;32m   2649\u001b[0m         color\u001b[39m=\u001b[39;49mcolor, label\u001b[39m=\u001b[39;49mlabel, stacked\u001b[39m=\u001b[39;49mstacked,\n\u001b[1;32m   2650\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m({\u001b[39m\"\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m\"\u001b[39;49m: data} \u001b[39mif\u001b[39;49;00m data \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m {}), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/matplotlib/__init__.py:1442\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1439\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m   1440\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(ax, \u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1441\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1442\u001b[0m         \u001b[39mreturn\u001b[39;00m func(ax, \u001b[39m*\u001b[39;49m\u001b[39mmap\u001b[39;49m(sanitize_sequence, args), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1444\u001b[0m     bound \u001b[39m=\u001b[39m new_sig\u001b[39m.\u001b[39mbind(ax, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1445\u001b[0m     auto_label \u001b[39m=\u001b[39m (bound\u001b[39m.\u001b[39marguments\u001b[39m.\u001b[39mget(label_namer)\n\u001b[1;32m   1446\u001b[0m                   \u001b[39mor\u001b[39;00m bound\u001b[39m.\u001b[39mkwargs\u001b[39m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/matplotlib/axes/_axes.py:6711\u001b[0m, in \u001b[0;36mAxes.hist\u001b[0;34m(self, x, bins, range, density, weights, cumulative, bottom, histtype, align, orientation, rwidth, log, color, label, stacked, **kwargs)\u001b[0m\n\u001b[1;32m   6709\u001b[0m \u001b[39mif\u001b[39;00m orientation \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mvertical\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   6710\u001b[0m     convert_units \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvert_xunits\n\u001b[0;32m-> 6711\u001b[0m     x \u001b[39m=\u001b[39m [\u001b[39m*\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_unit_info([(\u001b[39m\"\u001b[39;49m\u001b[39mx\u001b[39;49m\u001b[39m\"\u001b[39;49m, x[\u001b[39m0\u001b[39;49m])], kwargs),\n\u001b[1;32m   6712\u001b[0m          \u001b[39m*\u001b[39m\u001b[39mmap\u001b[39m(convert_units, x[\u001b[39m1\u001b[39m:])]\n\u001b[1;32m   6713\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# horizontal\u001b[39;00m\n\u001b[1;32m   6714\u001b[0m     convert_units \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvert_yunits\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/matplotlib/axes/_base.py:2549\u001b[0m, in \u001b[0;36m_AxesBase._process_unit_info\u001b[0;34m(self, datasets, kwargs, convert)\u001b[0m\n\u001b[1;32m   2547\u001b[0m     \u001b[39m# Update from data if axis is already set but no unit is set yet.\u001b[39;00m\n\u001b[1;32m   2548\u001b[0m     \u001b[39mif\u001b[39;00m axis \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m axis\u001b[39m.\u001b[39mhave_units():\n\u001b[0;32m-> 2549\u001b[0m         axis\u001b[39m.\u001b[39;49mupdate_units(data)\n\u001b[1;32m   2550\u001b[0m \u001b[39mfor\u001b[39;00m axis_name, axis \u001b[39min\u001b[39;00m axis_map\u001b[39m.\u001b[39mitems():\n\u001b[1;32m   2551\u001b[0m     \u001b[39m# Return if no axis is set.\u001b[39;00m\n\u001b[1;32m   2552\u001b[0m     \u001b[39mif\u001b[39;00m axis \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/matplotlib/axis.py:1675\u001b[0m, in \u001b[0;36mAxis.update_units\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1673\u001b[0m neednew \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconverter \u001b[39m!=\u001b[39m converter\n\u001b[1;32m   1674\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconverter \u001b[39m=\u001b[39m converter\n\u001b[0;32m-> 1675\u001b[0m default \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconverter\u001b[39m.\u001b[39;49mdefault_units(data, \u001b[39mself\u001b[39;49m)\n\u001b[1;32m   1676\u001b[0m \u001b[39mif\u001b[39;00m default \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munits \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1677\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_units(default)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/matplotlib/category.py:105\u001b[0m, in \u001b[0;36mStrCategoryConverter.default_units\u001b[0;34m(data, axis)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[39m# the conversion call stack is default_units -> axis_info -> convert\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[39mif\u001b[39;00m axis\u001b[39m.\u001b[39munits \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 105\u001b[0m     axis\u001b[39m.\u001b[39mset_units(UnitData(data))\n\u001b[1;32m    106\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    107\u001b[0m     axis\u001b[39m.\u001b[39munits\u001b[39m.\u001b[39mupdate(data)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/matplotlib/category.py:181\u001b[0m, in \u001b[0;36mUnitData.__init__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_counter \u001b[39m=\u001b[39m itertools\u001b[39m.\u001b[39mcount()\n\u001b[1;32m    180\u001b[0m \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 181\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupdate(data)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/matplotlib/category.py:219\u001b[0m, in \u001b[0;36mUnitData.update\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    216\u001b[0m _api\u001b[39m.\u001b[39mcheck_isinstance((\u001b[39mstr\u001b[39m, \u001b[39mbytes\u001b[39m), value\u001b[39m=\u001b[39mval)\n\u001b[1;32m    217\u001b[0m \u001b[39mif\u001b[39;00m convertible:\n\u001b[1;32m    218\u001b[0m     \u001b[39m# this will only be called so long as convertible is True.\u001b[39;00m\n\u001b[0;32m--> 219\u001b[0m     convertible \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_str_is_convertible(val)\n\u001b[1;32m    220\u001b[0m \u001b[39mif\u001b[39;00m val \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mapping:\n\u001b[1;32m    221\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mapping[val] \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_counter)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/matplotlib/category.py:192\u001b[0m, in \u001b[0;36mUnitData._str_is_convertible\u001b[0;34m(val)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[1;32m    191\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 192\u001b[0m         dateutil\u001b[39m.\u001b[39;49mparser\u001b[39m.\u001b[39;49mparse(val)\n\u001b[1;32m    193\u001b[0m     \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m):\n\u001b[1;32m    194\u001b[0m         \u001b[39m# TypeError if dateutil >= 2.8.1 else ValueError\u001b[39;00m\n\u001b[1;32m    195\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/dateutil/parser/_parser.py:1368\u001b[0m, in \u001b[0;36mparse\u001b[0;34m(timestr, parserinfo, **kwargs)\u001b[0m\n\u001b[1;32m   1366\u001b[0m     \u001b[39mreturn\u001b[39;00m parser(parserinfo)\u001b[39m.\u001b[39mparse(timestr, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1367\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1368\u001b[0m     \u001b[39mreturn\u001b[39;00m DEFAULTPARSER\u001b[39m.\u001b[39;49mparse(timestr, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/dateutil/parser/_parser.py:640\u001b[0m, in \u001b[0;36mparser.parse\u001b[0;34m(self, timestr, default, ignoretz, tzinfos, **kwargs)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[39mif\u001b[39;00m default \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    637\u001b[0m     default \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mdatetime\u001b[39m.\u001b[39mnow()\u001b[39m.\u001b[39mreplace(hour\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, minute\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,\n\u001b[1;32m    638\u001b[0m                                               second\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, microsecond\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m--> 640\u001b[0m res, skipped_tokens \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parse(timestr, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    642\u001b[0m \u001b[39mif\u001b[39;00m res \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    643\u001b[0m     \u001b[39mraise\u001b[39;00m ParserError(\u001b[39m\"\u001b[39m\u001b[39mUnknown string format: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, timestr)\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/dateutil/parser/_parser.py:719\u001b[0m, in \u001b[0;36mparser._parse\u001b[0;34m(self, timestr, dayfirst, yearfirst, fuzzy, fuzzy_with_tokens)\u001b[0m\n\u001b[1;32m    716\u001b[0m     yearfirst \u001b[39m=\u001b[39m info\u001b[39m.\u001b[39myearfirst\n\u001b[1;32m    718\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result()\n\u001b[0;32m--> 719\u001b[0m l \u001b[39m=\u001b[39m _timelex\u001b[39m.\u001b[39;49msplit(timestr)         \u001b[39m# Splits the timestr into tokens\u001b[39;00m\n\u001b[1;32m    721\u001b[0m skipped_idxs \u001b[39m=\u001b[39m []\n\u001b[1;32m    723\u001b[0m \u001b[39m# year/month/day list\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/dateutil/parser/_parser.py:201\u001b[0m, in \u001b[0;36m_timelex.split\u001b[0;34m(cls, s)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    200\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msplit\u001b[39m(\u001b[39mcls\u001b[39m, s):\n\u001b[0;32m--> 201\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(\u001b[39mcls\u001b[39;49m(s))\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/dateutil/parser/_parser.py:62\u001b[0m, in \u001b[0;36m_timelex.__init__\u001b[0;34m(self, instream)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39m_timelex\u001b[39;00m(\u001b[39mobject\u001b[39m):\n\u001b[1;32m     59\u001b[0m     \u001b[39m# Fractional seconds are sometimes split by a comma\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     _split_decimal \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39mcompile(\u001b[39m\"\u001b[39m\u001b[39m([.,])\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 62\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, instream):\n\u001b[1;32m     63\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(instream, (\u001b[39mbytes\u001b[39m, \u001b[39mbytearray\u001b[39m)):\n\u001b[1;32m     64\u001b[0m             instream \u001b[39m=\u001b[39m instream\u001b[39m.\u001b[39mdecode()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(tweetsdf.dropna(subset=['hashtags'])['date'])\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlim(pd.Timestamp('2009-01-01'), pd.Timestamp('2010-07-31'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting date field to datetime object\n",
    "tweetsdf['date'] = pd.to_datetime(tweetsdf['date'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Positive Event Impact\n",
    "Positive events:\n",
    "- Christmas/Holiday season 2009 \n",
    "- October 2009 NASA launching Ares-I X Mission \n",
    "- Fourth of July 2009 Statue of Liberty reopening\n",
    "- 2010 Winter Olympics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dates/Starts of positive events\n",
    "positiveEventDates = {\n",
    "    'christmas': pd.Timestamp('2009-12-25'),\n",
    "    'nasa': pd.Timestamp('2009-10-28'),\n",
    "    'liberty': pd.Timestamp('2009-07-04'),\n",
    "    'olympics': pd.Timestamp('2010-02-12')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotAvgHappiness(event, keywords, eventName, offset:int = 14, tweetsdf:pd.DataFrame =  tweetsdf, positiveEventDates:dict = positiveEventDates):\n",
    "    dateOffset = pd.DateOffset(days=offset)\n",
    "    # Filtering for tweets that are within two weeks of event\n",
    "    filteredTweets = tweetsdf[(tweetsdf['date'] >= (positiveEventDates[event] - dateOffset)) & (tweetsdf['date'] <= (positiveEventDates[event] + dateOffset))]\n",
    "    newDF = filteredTweets.copy()\n",
    "    newDF.loc[:,'containsKeywords'] = newDF['original_tweet'].str.contains('|'.join(keywords) if len(keywords) > 1 else keywords[0])\n",
    "    newDF.loc[:, 'all'] = 1  # Add a constant column\n",
    "\n",
    "    aggTweets = newDF.groupby(['containsKeywords', pd.Grouper(key='date', freq='D')]).mean(numeric_only=True)\n",
    "    aggTweets = aggTweets.reset_index().set_index('date')\n",
    "\n",
    "    allTweets = newDF.groupby(pd.Grouper(key='date', freq='D')).mean(numeric_only=True)\n",
    "    allTweets['containsKeywords'] = 'All'  # Add a label for the new line\n",
    "\n",
    "    # Combine the DataFrames and sort by date\n",
    "    aggTweets = pd.concat([aggTweets, allTweets]).sort_index()\n",
    "\n",
    "    # Plotting distribution of tweet scores around date\n",
    "    plot = px.line(\n",
    "        data_frame=aggTweets,\n",
    "        x=aggTweets.index,\n",
    "        y=aggTweets.score,\n",
    "        color=aggTweets['containsKeywords'],\n",
    "        title=f'Average Happiness Score for {eventName}',\n",
    "        labels = {'date':'Date','score':'Avg. Happiness Score', 'containsKeywords': 'Contains Keywords'}\n",
    "    )\n",
    "\n",
    "    return plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performTtest(event, offset:int = 14, tweetsdf:pd.DataFrame =  tweetsdf, positiveEventDates:dict = positiveEventDates):\n",
    "    dateOffset = pd.DateOffset(days=offset)\n",
    "\n",
    "    # Group 1 = pre\n",
    "    # Group 2 = post\n",
    "    group1 = tweetsdf[(tweetsdf['date'] >= (positiveEventDates[event] - dateOffset)) & (tweetsdf['date'] < positiveEventDates[event])]['score']\n",
    "    group2 = tweetsdf[(tweetsdf['date'] <= (positiveEventDates[event] + dateOffset)) & (tweetsdf['date'] > positiveEventDates[event])]['score']\n",
    "\n",
    "    # Check for normality assumption using Shapiro-Wilk test\n",
    "    stat1, p1 = ss.shapiro(group1)\n",
    "    stat2, p2 = ss.shapiro(group2)\n",
    "    alpha = 0.05\n",
    "\n",
    "    if p1 > alpha and p2 > alpha:\n",
    "        print('Both samples are normally distributed.')\n",
    "    else:\n",
    "        print('At least one sample is not normally distributed. However, sample size is large enough to ignore.')\n",
    "\n",
    "    # Check for equal variance assumption using Levene's test\n",
    "    stat, p = ss.levene(group1, group2)\n",
    "    if p > alpha:\n",
    "        var = True\n",
    "        print('Variances are equal.')\n",
    "    else:\n",
    "        var = False\n",
    "        print('Variances are not equal.')\n",
    "\n",
    "    # Perform t-test or welsch t-test assuming \n",
    "    t, p_final = ss.ttest_ind(group1, group2, equal_var=False)\n",
    "    if p > alpha:\n",
    "        print(f'There is no significant difference between the groups. p = {p_final}. var = {var}')\n",
    "    else:\n",
    "        print(f'There is a significant difference between the groups. p = {p_final}. var = {var}')\n",
    "\n",
    "    return (p_final, (group1.mean(), len(group1)), (group2.mean(), len(group2)))\n",
    "\n",
    "\n",
    "\n",
    "def performUtest(event, offset:int = 14, tweetsdf:pd.DataFrame =  tweetsdf, positiveEventDates:dict = positiveEventDates):\n",
    "    dateOffset = pd.DateOffset(days=offset)\n",
    "\n",
    "    # Group 1 = pre\n",
    "    # Group 2 = post\n",
    "    group1 = tweetsdf[(tweetsdf['date'] >= (positiveEventDates[event] - dateOffset)) & (tweetsdf['date'] < positiveEventDates[event])]['score']\n",
    "    group2 = tweetsdf[(tweetsdf['date'] <= (positiveEventDates[event] + dateOffset)) & (tweetsdf['date'] > positiveEventDates[event])]['score']\n",
    "\n",
    "    # Perform Mann-Whitney U test\n",
    "    statistic, p_final = ss.mannwhitneyu(group1, group2)\n",
    "\n",
    "    return (p_final, (group1.mean(), len(group1)), (group2.mean(), len(group2)))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Christmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scipy/stats/_morestats.py:1816: UserWarning:\n",
      "\n",
      "p-value may not be accurate for N > 5000.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are not equal.\n",
      "There is a significant difference between the groups. p = 3.9666063778648937e-29. var = False\n",
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are not equal.\n",
      "There is a significant difference between the groups. p = 1.3780060236716214e-10. var = False\n",
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are not equal.\n",
      "There is a significant difference between the groups. p = 3.806059030298258e-09. var = False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sj/h8ss6gyd3v3ch7qgcmgk8sjm0000gn/T/ipykernel_10930/1537043750.py:98: FutureWarning:\n",
      "\n",
      "this method is deprecated in favour of `Styler.to_html()`\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading page (1/2)\n",
      "Rendering (2/2)                                                    \n",
      "Done                                                               \n",
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are not equal.\n",
      "There is a significant difference between the groups. p = 0.0018100748521344236. var = False\n",
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are not equal.\n",
      "There is a significant difference between the groups. p = 0.0004762924819336148. var = False\n",
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are not equal.\n",
      "There is a significant difference between the groups. p = 0.0006012032905345531. var = False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sj/h8ss6gyd3v3ch7qgcmgk8sjm0000gn/T/ipykernel_10930/1537043750.py:163: FutureWarning:\n",
      "\n",
      "this method is deprecated in favour of `Styler.to_html()`\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading page (1/2)\n",
      "Rendering (2/2)                                                    \n",
      "Done                                                               \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining event and keyword\n",
    "event = 'christmas' \n",
    "keyword = 'christmas'\n",
    "dateOffset = pd.DateOffset(days=14)\n",
    "keywords = ['christmas']\n",
    "title = 'Christmas'\n",
    "\n",
    "# Defining where to store plots\n",
    "plotFile = '../plots/christmas'\n",
    "figW = 800\n",
    "figH = 600\n",
    "\n",
    "# Plotting average happiness around 28-day period for all data\n",
    "plotAvgHappiness(event, keywords, title, 14).write_image(f\"{plotFile}/avgHap28day.png\", format=\"png\", width=figW, height=figH)\n",
    "\n",
    "# Graphing keyword freq \n",
    "## Whole dataset\n",
    "keywordCountsDF  = pd.DataFrame({'date': tweetsdf['date'],'bool':tweetsdf['original_tweet'].str.contains('|'.join(keywords) if len(keywords)>1 else keywords[0])}).groupby(pd.Grouper(key='date', freq='D')).sum()\n",
    "\n",
    "# Plotting keyword freq \n",
    "px.line(\n",
    "    data_frame=keywordCountsDF,\n",
    "    x=keywordCountsDF.index,\n",
    "    y=keywordCountsDF['bool'],\n",
    "    labels={'bool': 'Frequency', 'date': 'Date'}\n",
    ").write_image(f\"{plotFile}/freqWhole.png\", format=\"png\", width=figW, height=figH)\n",
    "\n",
    "## Just 28 days\n",
    "filteredKeywordCountDF = keywordCountsDF.loc[(keywordCountsDF.index >= (positiveEventDates[event] - dateOffset)) & (keywordCountsDF.index <= positiveEventDates[event] + dateOffset)]\n",
    "\n",
    "# Plotting keyword freq around date\n",
    "px.line(\n",
    "    data_frame=filteredKeywordCountDF,\n",
    "    x=filteredKeywordCountDF.index,\n",
    "    y=filteredKeywordCountDF['bool'],\n",
    "    labels={'bool': 'Frequency', 'date': 'Date'}\n",
    ").write_image(f\"{plotFile}/freq28Day.png\", format=\"png\", width=figW, height=figH)\n",
    "\n",
    "# Performing Welsch t-Tests on all data\n",
    "## 28-day\n",
    "t28pValue, t28preData, t28postData = performTtest(event, 14)\n",
    "t28diff = t28postData[0] - t28preData[0]\n",
    "\n",
    "## 14-day\n",
    "t14pValue, t14preData, t14postData = performTtest(event, 7)\n",
    "t14diff = t14postData[0] - t14preData[0]\n",
    "\n",
    "## 6-day\n",
    "t6pValue, t6preData, t6postData = performTtest(event, 3)\n",
    "t6diff = t6postData[0] - t6preData[0]\n",
    "\n",
    "# Performing Mann-Whitney u-Tests on all data\n",
    "## 28-day\n",
    "u28pValue, u28preData, u28postData = performUtest(event, 14)\n",
    "u28diff = u28postData[0] - u28preData[0]\n",
    "\n",
    "## 14-day\n",
    "u14pValue, u14preData, u14postData = performUtest(event, 7)\n",
    "u14diff = u14postData[0] - u14preData[0]\n",
    "\n",
    "## 6-day\n",
    "u6pValue, u6preData, u6postData = performUtest(event, 3)\n",
    "u6diff = u6postData[0] - u6preData[0]\n",
    "\n",
    "# Creating table \n",
    "tableData = {\n",
    "    'Time Period': ['28 days', '14 days', '6 days'], \n",
    "    'Pre-Group Avg. Happiness': [t28preData[0], t14preData[0], t6preData[0]],\n",
    "    'Post-Group Avg. Happiness': [t28postData[0], t14postData[0], t6postData[0]],\n",
    "    'Difference in Avg. Happiness': [t28diff, t14diff, t6diff],\n",
    "    'Sample Size Pre-Group': [t28preData[1], t14preData[1], t6preData[1]],\n",
    "    'Sample Size Post-Group': [t28postData[1], t14postData[1], t6postData[1]],\n",
    "    'Welch\\'s t-Test p-value': [t28pValue, t14pValue, t6pValue],\n",
    "    'Mann-Whitney U test p-value': [u28pValue, u14pValue, u6pValue],\n",
    "}\n",
    "\n",
    "table = pd.DataFrame(tableData)\n",
    "styledTable = table.style.format({'Welch\\'s t-Test p-value': '{:.2e}', 'Mann-Whitney U test p-value': '{:.2e}'})\n",
    "styledTable = styledTable.set_properties(**{\n",
    "    'text-align': 'center',\n",
    "    'font-size': '14pt',\n",
    "    'font-family': 'Arial, sans-serif',\n",
    "    'border-collapse': 'collapse',\n",
    "    'border': '1px solid #ddd',\n",
    "    'background-color': '#f7f7f7',\n",
    "    'color': '#333',\n",
    "    'padding': '10px',\n",
    "}).set_table_styles([{    'selector': 'th',    'props': [        ('background-color', '#4CAF50'),        ('color', 'white'),        ('border-top', '1px solid #ddd'),        ('border-bottom', '1px solid #ddd'),        ('font-weight', 'bold'),        ('padding', '10px')    ]\n",
    "}, {\n",
    "    'selector': 'td',\n",
    "    'props': [\n",
    "        ('border-top', '1px solid #ddd'),\n",
    "        ('border-bottom', '1px solid #ddd'),\n",
    "        ('padding', '10px')\n",
    "    ]\n",
    "}])\n",
    "\n",
    "html = styledTable.render()\n",
    "\n",
    "# Save HTML as PNG image using imgkit\n",
    "imgkit.from_string(html, f'{plotFile}/{event}AllData.png')\n",
    "\n",
    "# Performing Welsch t-Tests on filtered data\n",
    "filteredTweetsDF = tweetsdf[tweetsdf['original_tweet'].str.contains('|'.join(keywords) if len(keywords)>1 else keywords[0])]\n",
    "## 28-day\n",
    "t28pValue, t28preData, t28postData = performTtest(event, 14, tweetsdf=filteredTweetsDF)\n",
    "t28diff = t28postData[0] - t28preData[0]\n",
    "\n",
    "## 14-day\n",
    "t14pValue, t14preData, t14postData = performTtest(event, 7, tweetsdf=filteredTweetsDF)\n",
    "t14diff = t14postData[0] - t14preData[0]\n",
    "\n",
    "## 6-day\n",
    "t6pValue, t6preData, t6postData = performTtest(event, 3, tweetsdf=filteredTweetsDF)\n",
    "t6diff = t6postData[0] - t6preData[0]\n",
    "\n",
    "# Performing Mann-Whitney u-Tests on all data\n",
    "## 28-day\n",
    "u28pValue, u28preData, u28postData = performUtest(event, 14, tweetsdf=filteredTweetsDF)\n",
    "u28diff = u28postData[0] - u28preData[0]\n",
    "\n",
    "## 14-day\n",
    "u14pValue, u14preData, u14postData = performUtest(event, 7, tweetsdf=filteredTweetsDF)\n",
    "u14diff = u14postData[0] - u14preData[0]\n",
    "\n",
    "## 6-day\n",
    "u6pValue, u6preData, u6postData = performUtest(event, 3, tweetsdf=filteredTweetsDF)\n",
    "u6diff = u6postData[0] - u6preData[0]\n",
    "\n",
    "# Creating table \n",
    "tableData = {\n",
    "    'Time Period': ['28 days', '14 days', '6 days'], \n",
    "    'Pre-Group Avg. Happiness': [t28preData[0], t14preData[0], t6preData[0]],\n",
    "    'Post-Group Avg. Happiness': [t28postData[0], t14postData[0], t6postData[0]],\n",
    "    'Difference in Avg. Happiness': [t28diff, t14diff, t6diff],\n",
    "    'Sample Size Pre-Group': [t28preData[1], t14preData[1], t6preData[1]],\n",
    "    'Sample Size Post-Group': [t28postData[1], t14postData[1], t6postData[1]],\n",
    "    'Welch\\'s t-Test p-value': [t28pValue, t14pValue, t6pValue],\n",
    "    'Mann-Whitney U test p-value': [u28pValue, u14pValue, u6pValue],\n",
    "}\n",
    "\n",
    "table = pd.DataFrame(tableData)\n",
    "styledTable = table.style.format({'Welch\\'s t-Test p-value': '{:.2e}', 'Mann-Whitney U test p-value': '{:.2e}'})\n",
    "styledTable = styledTable.set_properties(**{\n",
    "    'text-align': 'center',\n",
    "    'font-size': '14pt',\n",
    "    'font-family': 'Arial, sans-serif',\n",
    "    'border-collapse': 'collapse',\n",
    "    'border': '1px solid #ddd',\n",
    "    'background-color': '#f7f7f7',\n",
    "    'color': '#333',\n",
    "    'padding': '10px',\n",
    "}).set_table_styles([{    'selector': 'th',    'props': [        ('background-color', '#4CAF50'),        ('color', 'white'),        ('border-top', '1px solid #ddd'),        ('border-bottom', '1px solid #ddd'),        ('font-weight', 'bold'),        ('padding', '10px')    ]\n",
    "}, {\n",
    "    'selector': 'td',\n",
    "    'props': [\n",
    "        ('border-top', '1px solid #ddd'),\n",
    "        ('border-bottom', '1px solid #ddd'),\n",
    "        ('padding', '10px')\n",
    "    ]\n",
    "}])\n",
    "\n",
    "html = styledTable.render()\n",
    "# Save HTML as PNG image using imgkit\n",
    "imgkit.from_string(html, f'{plotFile}/{event}FilteredData.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourth of July"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scipy/stats/_morestats.py:1816: UserWarning:\n",
      "\n",
      "p-value may not be accurate for N > 5000.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are equal.\n",
      "There is no significant difference between the groups. p = 1.1242605648619732e-10. var = True\n",
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are equal.\n",
      "There is no significant difference between the groups. p = 0.02554515254606727. var = True\n",
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are equal.\n",
      "There is no significant difference between the groups. p = 0.844521361722606. var = True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sj/h8ss6gyd3v3ch7qgcmgk8sjm0000gn/T/ipykernel_10930/2951631719.py:97: FutureWarning:\n",
      "\n",
      "this method is deprecated in favour of `Styler.to_html()`\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading page (1/2)\n",
      "Rendering (2/2)                                                    \n",
      "Done                                                               \n",
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are equal.\n",
      "There is no significant difference between the groups. p = 0.433155570101458. var = True\n",
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are equal.\n",
      "There is no significant difference between the groups. p = 0.22329612437766083. var = True\n",
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are not equal.\n",
      "There is a significant difference between the groups. p = 0.21582041307940997. var = False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sj/h8ss6gyd3v3ch7qgcmgk8sjm0000gn/T/ipykernel_10930/2951631719.py:162: FutureWarning:\n",
      "\n",
      "this method is deprecated in favour of `Styler.to_html()`\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading page (1/2)\n",
      "Rendering (2/2)                                                    \n",
      "Done                                                               \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining event and keyword\n",
    "event = 'liberty' \n",
    "dateOffset = pd.DateOffset(days=14)\n",
    "keywords = ['liberty', 'fourth', 'july', 'freedom']\n",
    "title = 'Fourth of July'\n",
    "\n",
    "# Defining where to store plots\n",
    "plotFile = '../plots/fourth'\n",
    "figW = 800\n",
    "figH = 600\n",
    "\n",
    "# Plotting average happiness around 28-day period for all data\n",
    "plotAvgHappiness(event, keywords, title, 14).write_image(f\"{plotFile}/avgHap28day.png\", format=\"png\", width=figW, height=figH)\n",
    "\n",
    "# Graphing keyword freq \n",
    "## Whole dataset\n",
    "keywordCountsDF  = pd.DataFrame({'date': tweetsdf['date'],'bool':tweetsdf['original_tweet'].str.contains('|'.join(keywords) if len(keywords)>1 else keywords[0])}).groupby(pd.Grouper(key='date', freq='D')).sum()\n",
    "\n",
    "# Plotting keyword freq \n",
    "px.line(\n",
    "    data_frame=keywordCountsDF,\n",
    "    x=keywordCountsDF.index,\n",
    "    y=keywordCountsDF['bool'],\n",
    "    labels={'bool': 'Frequency', 'date': 'Date'}\n",
    ").write_image(f\"{plotFile}/freqWhole.png\", format=\"png\", width=figW, height=figH)\n",
    "\n",
    "## Just 28 days\n",
    "filteredKeywordCountDF = keywordCountsDF.loc[(keywordCountsDF.index >= (positiveEventDates[event] - dateOffset)) & (keywordCountsDF.index <= positiveEventDates[event] + dateOffset)]\n",
    "\n",
    "# Plotting keyword freq around date\n",
    "px.line(\n",
    "    data_frame=filteredKeywordCountDF,\n",
    "    x=filteredKeywordCountDF.index,\n",
    "    y=filteredKeywordCountDF['bool'],\n",
    "    labels={'bool': 'Frequency', 'date': 'Date'}\n",
    ").write_image(f\"{plotFile}/freq28Day.png\", format=\"png\", width=figW, height=figH)\n",
    "\n",
    "# Performing Welsch t-Tests on all data\n",
    "## 28-day\n",
    "t28pValue, t28preData, t28postData = performTtest(event, 14)\n",
    "t28diff = t28postData[0] - t28preData[0]\n",
    "\n",
    "## 14-day\n",
    "t14pValue, t14preData, t14postData = performTtest(event, 7)\n",
    "t14diff = t14postData[0] - t14preData[0]\n",
    "\n",
    "## 6-day\n",
    "t6pValue, t6preData, t6postData = performTtest(event, 3)\n",
    "t6diff = t6postData[0] - t6preData[0]\n",
    "\n",
    "# Performing Mann-Whitney u-Tests on all data\n",
    "## 28-day\n",
    "u28pValue, u28preData, u28postData = performUtest(event, 14)\n",
    "u28diff = u28postData[0] - u28preData[0]\n",
    "\n",
    "## 14-day\n",
    "u14pValue, u14preData, u14postData = performUtest(event, 7)\n",
    "u14diff = u14postData[0] - u14preData[0]\n",
    "\n",
    "## 6-day\n",
    "u6pValue, u6preData, u6postData = performUtest(event, 3)\n",
    "u6diff = u6postData[0] - u6preData[0]\n",
    "\n",
    "# Creating table \n",
    "tableData = {\n",
    "    'Time Period': ['28 days', '14 days', '6 days'], \n",
    "    'Pre-Group Avg. Happiness': [t28preData[0], t14preData[0], t6preData[0]],\n",
    "    'Post-Group Avg. Happiness': [t28postData[0], t14postData[0], t6postData[0]],\n",
    "    'Difference in Avg. Happiness': [t28diff, t14diff, t6diff],\n",
    "    'Sample Size Pre-Group': [t28preData[1], t14preData[1], t6preData[1]],\n",
    "    'Sample Size Post-Group': [t28postData[1], t14postData[1], t6postData[1]],\n",
    "    'Welch\\'s t-Test p-value': [t28pValue, t14pValue, t6pValue],\n",
    "    'Mann-Whitney U test p-value': [u28pValue, u14pValue, u6pValue],\n",
    "}\n",
    "\n",
    "table = pd.DataFrame(tableData)\n",
    "styledTable = table.style.format({'Welch\\'s t-Test p-value': '{:.2e}', 'Mann-Whitney U test p-value': '{:.2e}'})\n",
    "styledTable = styledTable.set_properties(**{\n",
    "    'text-align': 'center',\n",
    "    'font-size': '14pt',\n",
    "    'font-family': 'Arial, sans-serif',\n",
    "    'border-collapse': 'collapse',\n",
    "    'border': '1px solid #ddd',\n",
    "    'background-color': '#f7f7f7',\n",
    "    'color': '#333',\n",
    "    'padding': '10px',\n",
    "}).set_table_styles([{    'selector': 'th',    'props': [        ('background-color', '#4CAF50'),        ('color', 'white'),        ('border-top', '1px solid #ddd'),        ('border-bottom', '1px solid #ddd'),        ('font-weight', 'bold'),        ('padding', '10px')    ]\n",
    "}, {\n",
    "    'selector': 'td',\n",
    "    'props': [\n",
    "        ('border-top', '1px solid #ddd'),\n",
    "        ('border-bottom', '1px solid #ddd'),\n",
    "        ('padding', '10px')\n",
    "    ]\n",
    "}])\n",
    "\n",
    "html = styledTable.render()\n",
    "\n",
    "# Save HTML as PNG image using imgkit\n",
    "imgkit.from_string(html, f'{plotFile}/{event}AllData.png')\n",
    "\n",
    "# Performing Welsch t-Tests on filtered data\n",
    "filteredTweetsDF = tweetsdf[tweetsdf['original_tweet'].str.contains('|'.join(keywords) if len(keywords)>1 else keywords[0])]\n",
    "## 28-day\n",
    "t28pValue, t28preData, t28postData = performTtest(event, 14, tweetsdf=filteredTweetsDF)\n",
    "t28diff = t28postData[0] - t28preData[0]\n",
    "\n",
    "## 14-day\n",
    "t14pValue, t14preData, t14postData = performTtest(event, 7, tweetsdf=filteredTweetsDF)\n",
    "t14diff = t14postData[0] - t14preData[0]\n",
    "\n",
    "## 6-day\n",
    "t6pValue, t6preData, t6postData = performTtest(event, 3, tweetsdf=filteredTweetsDF)\n",
    "t6diff = t6postData[0] - t6preData[0]\n",
    "\n",
    "# Performing Mann-Whitney u-Tests on all data\n",
    "## 28-day\n",
    "u28pValue, u28preData, u28postData = performUtest(event, 14, tweetsdf=filteredTweetsDF)\n",
    "u28diff = u28postData[0] - u28preData[0]\n",
    "\n",
    "## 14-day\n",
    "u14pValue, u14preData, u14postData = performUtest(event, 7, tweetsdf=filteredTweetsDF)\n",
    "u14diff = u14postData[0] - u14preData[0]\n",
    "\n",
    "## 6-day\n",
    "u6pValue, u6preData, u6postData = performUtest(event, 3, tweetsdf=filteredTweetsDF)\n",
    "u6diff = u6postData[0] - u6preData[0]\n",
    "\n",
    "# Creating table \n",
    "tableData = {\n",
    "    'Time Period': ['28 days', '14 days', '6 days'], \n",
    "    'Pre-Group Avg. Happiness': [t28preData[0], t14preData[0], t6preData[0]],\n",
    "    'Post-Group Avg. Happiness': [t28postData[0], t14postData[0], t6postData[0]],\n",
    "    'Difference in Avg. Happiness': [t28diff, t14diff, t6diff],\n",
    "    'Sample Size Pre-Group': [t28preData[1], t14preData[1], t6preData[1]],\n",
    "    'Sample Size Post-Group': [t28postData[1], t14postData[1], t6postData[1]],\n",
    "    'Welch\\'s t-Test p-value': [t28pValue, t14pValue, t6pValue],\n",
    "    'Mann-Whitney U test p-value': [u28pValue, u14pValue, u6pValue],\n",
    "}\n",
    "\n",
    "table = pd.DataFrame(tableData)\n",
    "styledTable = table.style.format({'Welch\\'s t-Test p-value': '{:.2e}', 'Mann-Whitney U test p-value': '{:.2e}'})\n",
    "styledTable = styledTable.set_properties(**{\n",
    "    'text-align': 'center',\n",
    "    'font-size': '14pt',\n",
    "    'font-family': 'Arial, sans-serif',\n",
    "    'border-collapse': 'collapse',\n",
    "    'border': '1px solid #ddd',\n",
    "    'background-color': '#f7f7f7',\n",
    "    'color': '#333',\n",
    "    'padding': '10px',\n",
    "}).set_table_styles([{    'selector': 'th',    'props': [        ('background-color', '#4CAF50'),        ('color', 'white'),        ('border-top', '1px solid #ddd'),        ('border-bottom', '1px solid #ddd'),        ('font-weight', 'bold'),        ('padding', '10px')    ]\n",
    "}, {\n",
    "    'selector': 'td',\n",
    "    'props': [\n",
    "        ('border-top', '1px solid #ddd'),\n",
    "        ('border-bottom', '1px solid #ddd'),\n",
    "        ('padding', '10px')\n",
    "    ]\n",
    "}])\n",
    "\n",
    "html = styledTable.render()\n",
    "# Save HTML as PNG image using imgkit\n",
    "imgkit.from_string(html, f'{plotFile}/{event}FilteredData.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nasa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scipy/stats/_morestats.py:1816: UserWarning:\n",
      "\n",
      "p-value may not be accurate for N > 5000.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are equal.\n",
      "There is no significant difference between the groups. p = 1.3680076830157677e-47. var = True\n",
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are equal.\n",
      "There is no significant difference between the groups. p = 4.3604547731598424e-10. var = True\n",
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are equal.\n",
      "There is no significant difference between the groups. p = 2.1191245081830973e-08. var = True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sj/h8ss6gyd3v3ch7qgcmgk8sjm0000gn/T/ipykernel_10930/2380736216.py:97: FutureWarning:\n",
      "\n",
      "this method is deprecated in favour of `Styler.to_html()`\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading page (1/2)\n",
      "Rendering (2/2)                                                    \n",
      "Done                                                               \n",
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are equal.\n",
      "There is no significant difference between the groups. p = 0.14969229003583767. var = True\n",
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are not equal.\n",
      "There is a significant difference between the groups. p = 0.7518618150420562. var = False\n",
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are not equal.\n",
      "There is a significant difference between the groups. p = 0.0006072376576150991. var = False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sj/h8ss6gyd3v3ch7qgcmgk8sjm0000gn/T/ipykernel_10930/2380736216.py:162: FutureWarning:\n",
      "\n",
      "this method is deprecated in favour of `Styler.to_html()`\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading page (1/2)\n",
      "Rendering (2/2)                                                    \n",
      "Done                                                               \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining event and keyword\n",
    "event = 'nasa' \n",
    "dateOffset = pd.DateOffset(days=14)\n",
    "keywords = ['nasa', 'NASA', 'space', 'rocket', 'launch']\n",
    "title = 'Nasa Space Launch'\n",
    "\n",
    "# Defining where to store plots\n",
    "plotFile = '../plots/nasa'\n",
    "figW = 800\n",
    "figH = 600\n",
    "\n",
    "# Plotting average happiness around 28-day period for all data\n",
    "plotAvgHappiness(event, keywords, title, 14).write_image(f\"{plotFile}/avgHap28day.png\", format=\"png\", width=figW, height=figH)\n",
    "\n",
    "# Graphing keyword freq \n",
    "## Whole dataset\n",
    "keywordCountsDF  = pd.DataFrame({'date': tweetsdf['date'],'bool':tweetsdf['original_tweet'].str.contains('|'.join(keywords) if len(keywords)>1 else keywords[0])}).groupby(pd.Grouper(key='date', freq='D')).sum()\n",
    "\n",
    "# Plotting keyword freq \n",
    "px.line(\n",
    "    data_frame=keywordCountsDF,\n",
    "    x=keywordCountsDF.index,\n",
    "    y=keywordCountsDF['bool'],\n",
    "    labels={'bool': 'Frequency', 'date': 'Date'}\n",
    ").write_image(f\"{plotFile}/freqWhole.png\", format=\"png\", width=figW, height=figH)\n",
    "\n",
    "## Just 28 days\n",
    "filteredKeywordCountDF = keywordCountsDF.loc[(keywordCountsDF.index >= (positiveEventDates[event] - dateOffset)) & (keywordCountsDF.index <= positiveEventDates[event] + dateOffset)]\n",
    "\n",
    "# Plotting keyword freq around date\n",
    "px.line(\n",
    "    data_frame=filteredKeywordCountDF,\n",
    "    x=filteredKeywordCountDF.index,\n",
    "    y=filteredKeywordCountDF['bool'],\n",
    "    labels={'bool': 'Frequency', 'date': 'Date'}\n",
    ").write_image(f\"{plotFile}/freq28Day.png\", format=\"png\", width=figW, height=figH)\n",
    "\n",
    "# Performing Welsch t-Tests on all data\n",
    "## 28-day\n",
    "t28pValue, t28preData, t28postData = performTtest(event, 14)\n",
    "t28diff = t28postData[0] - t28preData[0]\n",
    "\n",
    "## 14-day\n",
    "t14pValue, t14preData, t14postData = performTtest(event, 7)\n",
    "t14diff = t14postData[0] - t14preData[0]\n",
    "\n",
    "## 6-day\n",
    "t6pValue, t6preData, t6postData = performTtest(event, 3)\n",
    "t6diff = t6postData[0] - t6preData[0]\n",
    "\n",
    "# Performing Mann-Whitney u-Tests on all data\n",
    "## 28-day\n",
    "u28pValue, u28preData, u28postData = performUtest(event, 14)\n",
    "u28diff = u28postData[0] - u28preData[0]\n",
    "\n",
    "## 14-day\n",
    "u14pValue, u14preData, u14postData = performUtest(event, 7)\n",
    "u14diff = u14postData[0] - u14preData[0]\n",
    "\n",
    "## 6-day\n",
    "u6pValue, u6preData, u6postData = performUtest(event, 3)\n",
    "u6diff = u6postData[0] - u6preData[0]\n",
    "\n",
    "# Creating table \n",
    "tableData = {\n",
    "    'Time Period': ['28 days', '14 days', '6 days'], \n",
    "    'Pre-Group Avg. Happiness': [t28preData[0], t14preData[0], t6preData[0]],\n",
    "    'Post-Group Avg. Happiness': [t28postData[0], t14postData[0], t6postData[0]],\n",
    "    'Difference in Avg. Happiness': [t28diff, t14diff, t6diff],\n",
    "    'Sample Size Pre-Group': [t28preData[1], t14preData[1], t6preData[1]],\n",
    "    'Sample Size Post-Group': [t28postData[1], t14postData[1], t6postData[1]],\n",
    "    'Welch\\'s t-Test p-value': [t28pValue, t14pValue, t6pValue],\n",
    "    'Mann-Whitney U test p-value': [u28pValue, u14pValue, u6pValue],\n",
    "}\n",
    "\n",
    "table = pd.DataFrame(tableData)\n",
    "styledTable = table.style.format({'Welch\\'s t-Test p-value': '{:.2e}', 'Mann-Whitney U test p-value': '{:.2e}'})\n",
    "styledTable = styledTable.set_properties(**{\n",
    "    'text-align': 'center',\n",
    "    'font-size': '14pt',\n",
    "    'font-family': 'Arial, sans-serif',\n",
    "    'border-collapse': 'collapse',\n",
    "    'border': '1px solid #ddd',\n",
    "    'background-color': '#f7f7f7',\n",
    "    'color': '#333',\n",
    "    'padding': '10px',\n",
    "}).set_table_styles([{    'selector': 'th',    'props': [        ('background-color', '#4CAF50'),        ('color', 'white'),        ('border-top', '1px solid #ddd'),        ('border-bottom', '1px solid #ddd'),        ('font-weight', 'bold'),        ('padding', '10px')    ]\n",
    "}, {\n",
    "    'selector': 'td',\n",
    "    'props': [\n",
    "        ('border-top', '1px solid #ddd'),\n",
    "        ('border-bottom', '1px solid #ddd'),\n",
    "        ('padding', '10px')\n",
    "    ]\n",
    "}])\n",
    "\n",
    "html = styledTable.render()\n",
    "\n",
    "# Save HTML as PNG image using imgkit\n",
    "imgkit.from_string(html, f'{plotFile}/{event}AllData.png')\n",
    "\n",
    "# Performing Welsch t-Tests on filtered data\n",
    "filteredTweetsDF = tweetsdf[tweetsdf['original_tweet'].str.contains('|'.join(keywords) if len(keywords)>1 else keywords[0])]\n",
    "## 28-day\n",
    "t28pValue, t28preData, t28postData = performTtest(event, 14, tweetsdf=filteredTweetsDF)\n",
    "t28diff = t28postData[0] - t28preData[0]\n",
    "\n",
    "## 14-day\n",
    "t14pValue, t14preData, t14postData = performTtest(event, 7, tweetsdf=filteredTweetsDF)\n",
    "t14diff = t14postData[0] - t14preData[0]\n",
    "\n",
    "## 6-day\n",
    "t6pValue, t6preData, t6postData = performTtest(event, 3, tweetsdf=filteredTweetsDF)\n",
    "t6diff = t6postData[0] - t6preData[0]\n",
    "\n",
    "# Performing Mann-Whitney u-Tests on all data\n",
    "## 28-day\n",
    "u28pValue, u28preData, u28postData = performUtest(event, 14, tweetsdf=filteredTweetsDF)\n",
    "u28diff = u28postData[0] - u28preData[0]\n",
    "\n",
    "## 14-day\n",
    "u14pValue, u14preData, u14postData = performUtest(event, 7, tweetsdf=filteredTweetsDF)\n",
    "u14diff = u14postData[0] - u14preData[0]\n",
    "\n",
    "## 6-day\n",
    "u6pValue, u6preData, u6postData = performUtest(event, 3, tweetsdf=filteredTweetsDF)\n",
    "u6diff = u6postData[0] - u6preData[0]\n",
    "\n",
    "# Creating table \n",
    "tableData = {\n",
    "    'Time Period': ['28 days', '14 days', '6 days'], \n",
    "    'Pre-Group Avg. Happiness': [t28preData[0], t14preData[0], t6preData[0]],\n",
    "    'Post-Group Avg. Happiness': [t28postData[0], t14postData[0], t6postData[0]],\n",
    "    'Difference in Avg. Happiness': [t28diff, t14diff, t6diff],\n",
    "    'Sample Size Pre-Group': [t28preData[1], t14preData[1], t6preData[1]],\n",
    "    'Sample Size Post-Group': [t28postData[1], t14postData[1], t6postData[1]],\n",
    "    'Welch\\'s t-Test p-value': [t28pValue, t14pValue, t6pValue],\n",
    "    'Mann-Whitney U test p-value': [u28pValue, u14pValue, u6pValue],\n",
    "}\n",
    "\n",
    "table = pd.DataFrame(tableData)\n",
    "styledTable = table.style.format({'Welch\\'s t-Test p-value': '{:.2e}', 'Mann-Whitney U test p-value': '{:.2e}'})\n",
    "styledTable = styledTable.set_properties(**{\n",
    "    'text-align': 'center',\n",
    "    'font-size': '14pt',\n",
    "    'font-family': 'Arial, sans-serif',\n",
    "    'border-collapse': 'collapse',\n",
    "    'border': '1px solid #ddd',\n",
    "    'background-color': '#f7f7f7',\n",
    "    'color': '#333',\n",
    "    'padding': '10px',\n",
    "}).set_table_styles([{    'selector': 'th',    'props': [        ('background-color', '#4CAF50'),        ('color', 'white'),        ('border-top', '1px solid #ddd'),        ('border-bottom', '1px solid #ddd'),        ('font-weight', 'bold'),        ('padding', '10px')    ]\n",
    "}, {\n",
    "    'selector': 'td',\n",
    "    'props': [\n",
    "        ('border-top', '1px solid #ddd'),\n",
    "        ('border-bottom', '1px solid #ddd'),\n",
    "        ('padding', '10px')\n",
    "    ]\n",
    "}])\n",
    "\n",
    "html = styledTable.render()\n",
    "# Save HTML as PNG image using imgkit\n",
    "imgkit.from_string(html, f'{plotFile}/{event}FilteredData.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Olympics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scipy/stats/_morestats.py:1816: UserWarning:\n",
      "\n",
      "p-value may not be accurate for N > 5000.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are not equal.\n",
      "There is a significant difference between the groups. p = 4.8564334302349805e-05. var = False\n",
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are equal.\n",
      "There is no significant difference between the groups. p = 0.01802254201682625. var = True\n",
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are not equal.\n",
      "There is a significant difference between the groups. p = 1.4578752666810718e-26. var = False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sj/h8ss6gyd3v3ch7qgcmgk8sjm0000gn/T/ipykernel_10930/190981692.py:97: FutureWarning:\n",
      "\n",
      "this method is deprecated in favour of `Styler.to_html()`\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading page (1/2)\n",
      "Rendering (2/2)                                                    \n",
      "Done                                                               \n",
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are not equal.\n",
      "There is a significant difference between the groups. p = 2.5512598307645826e-06. var = False\n",
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are equal.\n",
      "There is no significant difference between the groups. p = 7.609213312855402e-06. var = True\n",
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are equal.\n",
      "There is no significant difference between the groups. p = 1.3049245455095034e-05. var = True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sj/h8ss6gyd3v3ch7qgcmgk8sjm0000gn/T/ipykernel_10930/190981692.py:162: FutureWarning:\n",
      "\n",
      "this method is deprecated in favour of `Styler.to_html()`\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading page (1/2)\n",
      "Rendering (2/2)                                                    \n",
      "Done                                                               \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining event and keyword\n",
    "event = 'olympics' \n",
    "dateOffset = pd.DateOffset(days=14)\n",
    "keywords = ['olympics', 'winter', 'sports']\n",
    "title = 'Winter Olympics'\n",
    "\n",
    "# Defining where to store plots\n",
    "plotFile = '../plots/olympics'\n",
    "figW = 800\n",
    "figH = 600\n",
    "\n",
    "# Plotting average happiness around 28-day period for all data\n",
    "plotAvgHappiness(event, keywords, title, 14).write_image(f\"{plotFile}/avgHap28day.png\", format=\"png\", width=figW, height=figH)\n",
    "\n",
    "# Graphing keyword freq \n",
    "## Whole dataset\n",
    "keywordCountsDF  = pd.DataFrame({'date': tweetsdf['date'],'bool':tweetsdf['original_tweet'].str.contains('|'.join(keywords) if len(keywords)>1 else keywords[0])}).groupby(pd.Grouper(key='date', freq='D')).sum()\n",
    "\n",
    "# Plotting keyword freq \n",
    "px.line(\n",
    "    data_frame=keywordCountsDF,\n",
    "    x=keywordCountsDF.index,\n",
    "    y=keywordCountsDF['bool'],\n",
    "    labels={'bool': 'Frequency', 'date': 'Date'}\n",
    ").write_image(f\"{plotFile}/freqWhole.png\", format=\"png\", width=figW, height=figH)\n",
    "\n",
    "## Just 28 days\n",
    "filteredKeywordCountDF = keywordCountsDF.loc[(keywordCountsDF.index >= (positiveEventDates[event] - dateOffset)) & (keywordCountsDF.index <= positiveEventDates[event] + dateOffset)]\n",
    "\n",
    "# Plotting keyword freq around date\n",
    "px.line(\n",
    "    data_frame=filteredKeywordCountDF,\n",
    "    x=filteredKeywordCountDF.index,\n",
    "    y=filteredKeywordCountDF['bool'],\n",
    "    labels={'bool': 'Frequency', 'date': 'Date'}\n",
    ").write_image(f\"{plotFile}/freq28Day.png\", format=\"png\", width=figW, height=figH)\n",
    "\n",
    "# Performing Welsch t-Tests on all data\n",
    "## 28-day\n",
    "t28pValue, t28preData, t28postData = performTtest(event, 14)\n",
    "t28diff = t28postData[0] - t28preData[0]\n",
    "\n",
    "## 14-day\n",
    "t14pValue, t14preData, t14postData = performTtest(event, 7)\n",
    "t14diff = t14postData[0] - t14preData[0]\n",
    "\n",
    "## 6-day\n",
    "t6pValue, t6preData, t6postData = performTtest(event, 3)\n",
    "t6diff = t6postData[0] - t6preData[0]\n",
    "\n",
    "# Performing Mann-Whitney u-Tests on all data\n",
    "## 28-day\n",
    "u28pValue, u28preData, u28postData = performUtest(event, 14)\n",
    "u28diff = u28postData[0] - u28preData[0]\n",
    "\n",
    "## 14-day\n",
    "u14pValue, u14preData, u14postData = performUtest(event, 7)\n",
    "u14diff = u14postData[0] - u14preData[0]\n",
    "\n",
    "## 6-day\n",
    "u6pValue, u6preData, u6postData = performUtest(event, 3)\n",
    "u6diff = u6postData[0] - u6preData[0]\n",
    "\n",
    "# Creating table \n",
    "tableData = {\n",
    "    'Time Period': ['28 days', '14 days', '6 days'], \n",
    "    'Pre-Group Avg. Happiness': [t28preData[0], t14preData[0], t6preData[0]],\n",
    "    'Post-Group Avg. Happiness': [t28postData[0], t14postData[0], t6postData[0]],\n",
    "    'Difference in Avg. Happiness': [t28diff, t14diff, t6diff],\n",
    "    'Sample Size Pre-Group': [t28preData[1], t14preData[1], t6preData[1]],\n",
    "    'Sample Size Post-Group': [t28postData[1], t14postData[1], t6postData[1]],\n",
    "    'Welch\\'s t-Test p-value': [t28pValue, t14pValue, t6pValue],\n",
    "    'Mann-Whitney U test p-value': [u28pValue, u14pValue, u6pValue],\n",
    "}\n",
    "\n",
    "table = pd.DataFrame(tableData)\n",
    "styledTable = table.style.format({'Welch\\'s t-Test p-value': '{:.2e}', 'Mann-Whitney U test p-value': '{:.2e}'})\n",
    "styledTable = styledTable.set_properties(**{\n",
    "    'text-align': 'center',\n",
    "    'font-size': '14pt',\n",
    "    'font-family': 'Arial, sans-serif',\n",
    "    'border-collapse': 'collapse',\n",
    "    'border': '1px solid #ddd',\n",
    "    'background-color': '#f7f7f7',\n",
    "    'color': '#333',\n",
    "    'padding': '10px',\n",
    "}).set_table_styles([{    'selector': 'th',    'props': [        ('background-color', '#4CAF50'),        ('color', 'white'),        ('border-top', '1px solid #ddd'),        ('border-bottom', '1px solid #ddd'),        ('font-weight', 'bold'),        ('padding', '10px')    ]\n",
    "}, {\n",
    "    'selector': 'td',\n",
    "    'props': [\n",
    "        ('border-top', '1px solid #ddd'),\n",
    "        ('border-bottom', '1px solid #ddd'),\n",
    "        ('padding', '10px')\n",
    "    ]\n",
    "}])\n",
    "\n",
    "html = styledTable.render()\n",
    "\n",
    "# Save HTML as PNG image using imgkit\n",
    "imgkit.from_string(html, f'{plotFile}/{event}AllData.png')\n",
    "\n",
    "# Performing Welsch t-Tests on filtered data\n",
    "filteredTweetsDF = tweetsdf[tweetsdf['original_tweet'].str.contains('|'.join(keywords) if len(keywords)>1 else keywords[0])]\n",
    "## 28-day\n",
    "t28pValue, t28preData, t28postData = performTtest(event, 14, tweetsdf=filteredTweetsDF)\n",
    "t28diff = t28postData[0] - t28preData[0]\n",
    "\n",
    "## 14-day\n",
    "t14pValue, t14preData, t14postData = performTtest(event, 7, tweetsdf=filteredTweetsDF)\n",
    "t14diff = t14postData[0] - t14preData[0]\n",
    "\n",
    "## 6-day\n",
    "t6pValue, t6preData, t6postData = performTtest(event, 3, tweetsdf=filteredTweetsDF)\n",
    "t6diff = t6postData[0] - t6preData[0]\n",
    "\n",
    "# Performing Mann-Whitney u-Tests on all data\n",
    "## 28-day\n",
    "u28pValue, u28preData, u28postData = performUtest(event, 14, tweetsdf=filteredTweetsDF)\n",
    "u28diff = u28postData[0] - u28preData[0]\n",
    "\n",
    "## 14-day\n",
    "u14pValue, u14preData, u14postData = performUtest(event, 7, tweetsdf=filteredTweetsDF)\n",
    "u14diff = u14postData[0] - u14preData[0]\n",
    "\n",
    "## 6-day\n",
    "u6pValue, u6preData, u6postData = performUtest(event, 3, tweetsdf=filteredTweetsDF)\n",
    "u6diff = u6postData[0] - u6preData[0]\n",
    "\n",
    "# Creating table \n",
    "tableData = {\n",
    "    'Time Period': ['28 days', '14 days', '6 days'], \n",
    "    'Pre-Group Avg. Happiness': [t28preData[0], t14preData[0], t6preData[0]],\n",
    "    'Post-Group Avg. Happiness': [t28postData[0], t14postData[0], t6postData[0]],\n",
    "    'Difference in Avg. Happiness': [t28diff, t14diff, t6diff],\n",
    "    'Sample Size Pre-Group': [t28preData[1], t14preData[1], t6preData[1]],\n",
    "    'Sample Size Post-Group': [t28postData[1], t14postData[1], t6postData[1]],\n",
    "    'Welch\\'s t-Test p-value': [t28pValue, t14pValue, t6pValue],\n",
    "    'Mann-Whitney U test p-value': [u28pValue, u14pValue, u6pValue],\n",
    "}\n",
    "\n",
    "table = pd.DataFrame(tableData)\n",
    "styledTable = table.style.format({'Welch\\'s t-Test p-value': '{:.2e}', 'Mann-Whitney U test p-value': '{:.2e}'})\n",
    "styledTable = styledTable.set_properties(**{\n",
    "    'text-align': 'center',\n",
    "    'font-size': '14pt',\n",
    "    'font-family': 'Arial, sans-serif',\n",
    "    'border-collapse': 'collapse',\n",
    "    'border': '1px solid #ddd',\n",
    "    'background-color': '#f7f7f7',\n",
    "    'color': '#333',\n",
    "    'padding': '10px',\n",
    "}).set_table_styles([{    'selector': 'th',    'props': [        ('background-color', '#4CAF50'),        ('color', 'white'),        ('border-top', '1px solid #ddd'),        ('border-bottom', '1px solid #ddd'),        ('font-weight', 'bold'),        ('padding', '10px')    ]\n",
    "}, {\n",
    "    'selector': 'td',\n",
    "    'props': [\n",
    "        ('border-top', '1px solid #ddd'),\n",
    "        ('border-bottom', '1px solid #ddd'),\n",
    "        ('padding', '10px')\n",
    "    ]\n",
    "}])\n",
    "\n",
    "html = styledTable.render()\n",
    "# Save HTML as PNG image using imgkit\n",
    "imgkit.from_string(html, f'{plotFile}/{event}FilteredData.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
