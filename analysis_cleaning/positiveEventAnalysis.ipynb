{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import scipy.stats as ss\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import imgkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>user_id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>original_tweet</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006-09-10 11:07:07</td>\n",
       "      <td>trying to figure out what this thing is</td>\n",
       "      <td>5622.0</td>\n",
       "      <td>39.1413</td>\n",
       "      <td>-84.506</td>\n",
       "      <td>NaN</td>\n",
       "      <td>trying to figure out what this thing is.</td>\n",
       "      <td>4.154872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-03-17 09:59:46</td>\n",
       "      <td>killing my land line</td>\n",
       "      <td>5622.0</td>\n",
       "      <td>39.1413</td>\n",
       "      <td>-84.506</td>\n",
       "      <td>NaN</td>\n",
       "      <td>killing my land line.</td>\n",
       "      <td>4.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-03-18 11:48:24</td>\n",
       "      <td>my expense report</td>\n",
       "      <td>5622.0</td>\n",
       "      <td>39.1413</td>\n",
       "      <td>-84.506</td>\n",
       "      <td>NaN</td>\n",
       "      <td>my expense report</td>\n",
       "      <td>4.275294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-03-21 12:20:05</td>\n",
       "      <td>putting down the llama book</td>\n",
       "      <td>5622.0</td>\n",
       "      <td>39.1413</td>\n",
       "      <td>-84.506</td>\n",
       "      <td>NaN</td>\n",
       "      <td>putting down the llama book.</td>\n",
       "      <td>4.258095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2007-04-23 16:33:41</td>\n",
       "      <td>releasing final art</td>\n",
       "      <td>5622.0</td>\n",
       "      <td>39.1413</td>\n",
       "      <td>-84.506</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Releasing Final Art.</td>\n",
       "      <td>4.528889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date                                    tweet  user_id  \\\n",
       "0  2006-09-10 11:07:07  trying to figure out what this thing is   5622.0   \n",
       "1  2007-03-17 09:59:46                     killing my land line   5622.0   \n",
       "2  2007-03-18 11:48:24                        my expense report   5622.0   \n",
       "3  2007-03-21 12:20:05              putting down the llama book   5622.0   \n",
       "5  2007-04-23 16:33:41                      releasing final art   5622.0   \n",
       "\n",
       "   latitude  longitude hashtags                            original_tweet  \\\n",
       "0   39.1413    -84.506      NaN  trying to figure out what this thing is.   \n",
       "1   39.1413    -84.506      NaN                     killing my land line.   \n",
       "2   39.1413    -84.506      NaN                         my expense report   \n",
       "3   39.1413    -84.506      NaN              putting down the llama book.   \n",
       "5   39.1413    -84.506      NaN                      Releasing Final Art.   \n",
       "\n",
       "      score  \n",
       "0  4.154872  \n",
       "1  4.375000  \n",
       "2  4.275294  \n",
       "3  4.258095  \n",
       "5  4.528889  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting DF\n",
    "tweetsdf = pd.read_csv('../data/finalScores.csv').dropna(subset=['score'])\n",
    "tweetsdf = tweetsdf.iloc[:,2:]\n",
    "tweetsdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>user_id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>original_tweet</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>2009-10-24 19:53:09</td>\n",
       "      <td>school of cock</td>\n",
       "      <td>753393.0</td>\n",
       "      <td>34.11410</td>\n",
       "      <td>-118.4068</td>\n",
       "      <td>oneletteroffmovies</td>\n",
       "      <td>@SarahKSilverman School of Cock #oneletteroffm...</td>\n",
       "      <td>4.192857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>2007-03-23 01:56:29</td>\n",
       "      <td>bomb this wont happen again i promise</td>\n",
       "      <td>1983121.0</td>\n",
       "      <td>45.31090</td>\n",
       "      <td>-122.7702</td>\n",
       "      <td>1</td>\n",
       "      <td>Bomb #1, This wont happen again, I promise!</td>\n",
       "      <td>4.245946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>2007-03-23 01:56:30</td>\n",
       "      <td>bomb this wont happen again i promise</td>\n",
       "      <td>1983121.0</td>\n",
       "      <td>45.31090</td>\n",
       "      <td>-122.7702</td>\n",
       "      <td>2</td>\n",
       "      <td>Bomb #2, This wont happen again, I promise!</td>\n",
       "      <td>4.245946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>2009-05-13 13:38:06</td>\n",
       "      <td>im sure im late with this but here you go</td>\n",
       "      <td>1925401.0</td>\n",
       "      <td>42.38890</td>\n",
       "      <td>-71.2423</td>\n",
       "      <td>imw051309</td>\n",
       "      <td>@gregorysimpson i'm sure i'm late with this bu...</td>\n",
       "      <td>3.956098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>2009-06-20 09:45:55</td>\n",
       "      <td>i also want to send support to everyone in ira...</td>\n",
       "      <td>1925401.0</td>\n",
       "      <td>42.38890</td>\n",
       "      <td>-71.2423</td>\n",
       "      <td>teaparty</td>\n",
       "      <td>@jillwhalen i also want to send support to eve...</td>\n",
       "      <td>4.078384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8681398</th>\n",
       "      <td>2010-03-16 12:17:28</td>\n",
       "      <td>trt shay was whoopin dat assstop lyin lol</td>\n",
       "      <td>58669408.0</td>\n",
       "      <td>43.02179</td>\n",
       "      <td>-83.6757</td>\n",
       "      <td>whenifirstmet</td>\n",
       "      <td>TRT @kyekye22: #whenifirstmet @DineroMEECH Sha...</td>\n",
       "      <td>4.132727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8681399</th>\n",
       "      <td>2010-03-16 12:17:51</td>\n",
       "      <td>rt he blew the games for us at this tournament...</td>\n",
       "      <td>58669408.0</td>\n",
       "      <td>43.02179</td>\n",
       "      <td>-83.6757</td>\n",
       "      <td>wheniirstmet</td>\n",
       "      <td>RT @smittylu: #wheniirstmet @DineroMEECH he bl...</td>\n",
       "      <td>3.944815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8681415</th>\n",
       "      <td>2010-03-16 12:58:33</td>\n",
       "      <td>just saw measurements  that is  i need  see th...</td>\n",
       "      <td>58669408.0</td>\n",
       "      <td>43.02179</td>\n",
       "      <td>-83.6757</td>\n",
       "      <td>unreal</td>\n",
       "      <td>Just saw @cherokeedassxxx measurements: 36-29-...</td>\n",
       "      <td>4.091636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8681423</th>\n",
       "      <td>2010-03-16 13:19:24</td>\n",
       "      <td>rtdineromeech it was at my hotel partyi though...</td>\n",
       "      <td>58669408.0</td>\n",
       "      <td>43.02179</td>\n",
       "      <td>-83.6757</td>\n",
       "      <td>whenifirstmet,nolie</td>\n",
       "      <td>RT @CharmaineBryant: #WhenIFirstMet--&gt;&gt;@Dinero...</td>\n",
       "      <td>3.905769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8681435</th>\n",
       "      <td>2010-03-16 20:03:37</td>\n",
       "      <td>rt he was  talking very loudly for no reason l...</td>\n",
       "      <td>58669408.0</td>\n",
       "      <td>43.02179</td>\n",
       "      <td>-83.6757</td>\n",
       "      <td>whenifirstmet</td>\n",
       "      <td>RT @Miyoko92: #whenifirstmet @DineroMEECH he w...</td>\n",
       "      <td>3.897447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>783446 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        date  \\\n",
       "94       2009-10-24 19:53:09   \n",
       "315      2007-03-23 01:56:29   \n",
       "317      2007-03-23 01:56:30   \n",
       "355      2009-05-13 13:38:06   \n",
       "363      2009-06-20 09:45:55   \n",
       "...                      ...   \n",
       "8681398  2010-03-16 12:17:28   \n",
       "8681399  2010-03-16 12:17:51   \n",
       "8681415  2010-03-16 12:58:33   \n",
       "8681423  2010-03-16 13:19:24   \n",
       "8681435  2010-03-16 20:03:37   \n",
       "\n",
       "                                                     tweet     user_id  \\\n",
       "94                                          school of cock    753393.0   \n",
       "315                  bomb this wont happen again i promise   1983121.0   \n",
       "317                  bomb this wont happen again i promise   1983121.0   \n",
       "355              im sure im late with this but here you go   1925401.0   \n",
       "363      i also want to send support to everyone in ira...   1925401.0   \n",
       "...                                                    ...         ...   \n",
       "8681398          trt shay was whoopin dat assstop lyin lol  58669408.0   \n",
       "8681399  rt he blew the games for us at this tournament...  58669408.0   \n",
       "8681415  just saw measurements  that is  i need  see th...  58669408.0   \n",
       "8681423  rtdineromeech it was at my hotel partyi though...  58669408.0   \n",
       "8681435  rt he was  talking very loudly for no reason l...  58669408.0   \n",
       "\n",
       "         latitude  longitude             hashtags  \\\n",
       "94       34.11410  -118.4068   oneletteroffmovies   \n",
       "315      45.31090  -122.7702                    1   \n",
       "317      45.31090  -122.7702                    2   \n",
       "355      42.38890   -71.2423            imw051309   \n",
       "363      42.38890   -71.2423             teaparty   \n",
       "...           ...        ...                  ...   \n",
       "8681398  43.02179   -83.6757        whenifirstmet   \n",
       "8681399  43.02179   -83.6757         wheniirstmet   \n",
       "8681415  43.02179   -83.6757               unreal   \n",
       "8681423  43.02179   -83.6757  whenifirstmet,nolie   \n",
       "8681435  43.02179   -83.6757        whenifirstmet   \n",
       "\n",
       "                                            original_tweet     score  \n",
       "94       @SarahKSilverman School of Cock #oneletteroffm...  4.192857  \n",
       "315            Bomb #1, This wont happen again, I promise!  4.245946  \n",
       "317            Bomb #2, This wont happen again, I promise!  4.245946  \n",
       "355      @gregorysimpson i'm sure i'm late with this bu...  3.956098  \n",
       "363      @jillwhalen i also want to send support to eve...  4.078384  \n",
       "...                                                    ...       ...  \n",
       "8681398  TRT @kyekye22: #whenifirstmet @DineroMEECH Sha...  4.132727  \n",
       "8681399  RT @smittylu: #wheniirstmet @DineroMEECH he bl...  3.944815  \n",
       "8681415  Just saw @cherokeedassxxx measurements: 36-29-...  4.091636  \n",
       "8681423  RT @CharmaineBryant: #WhenIFirstMet-->>@Dinero...  3.905769  \n",
       "8681435  RT @Miyoko92: #whenifirstmet @DineroMEECH he w...  3.897447  \n",
       "\n",
       "[783446 rows x 8 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetsdf.dropna(subset=['hashtags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting date field to datetime object\n",
    "tweetsdf['date'] = pd.to_datetime(tweetsdf['date'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Positive Event Impact\n",
    "Positive events:\n",
    "- Christmas/Holiday season 2009 \n",
    "- October 2009 NASA launching Ares-I X Mission \n",
    "- Fourth of July 2009 Statue of Liberty reopening\n",
    "- 2010 Winter Olympics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dates/Starts of positive events\n",
    "positiveEventDates = {\n",
    "    'christmas': pd.Timestamp('2009-12-25'),\n",
    "    'nasa': pd.Timestamp('2009-10-28'),\n",
    "    'liberty': pd.Timestamp('2009-07-04'),\n",
    "    'olympics': pd.Timestamp('2010-02-12')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotAvgHappiness(event, keywords, eventName, offset:int = 14, tweetsdf:pd.DataFrame =  tweetsdf, positiveEventDates:dict = positiveEventDates):\n",
    "    dateOffset = pd.DateOffset(days=offset)\n",
    "    # Filtering for tweets that are within two weeks of event\n",
    "    filteredTweets = tweetsdf[(tweetsdf['date'] >= (positiveEventDates[event] - dateOffset)) & (tweetsdf['date'] <= (positiveEventDates[event] + dateOffset))]\n",
    "    newDF = filteredTweets.copy()\n",
    "    newDF.loc[:,'containsKeywords'] = newDF['original_tweet'].str.contains('|'.join(keywords) if len(keywords) > 1 else keywords[0])\n",
    "    newDF.loc[:, 'all'] = 1  # Add a constant column\n",
    "\n",
    "    aggTweets = newDF.groupby(['containsKeywords', pd.Grouper(key='date', freq='D')]).mean(numeric_only=True)\n",
    "    aggTweets = aggTweets.reset_index().set_index('date')\n",
    "\n",
    "    allTweets = newDF.groupby(pd.Grouper(key='date', freq='D')).mean(numeric_only=True)\n",
    "    allTweets['containsKeywords'] = 'All'  # Add a label for the new line\n",
    "\n",
    "    # Combine the DataFrames and sort by date\n",
    "    aggTweets = pd.concat([aggTweets, allTweets]).sort_index()\n",
    "\n",
    "    # Plotting distribution of tweet scores around date\n",
    "    plot = px.line(\n",
    "        data_frame=aggTweets,\n",
    "        x=aggTweets.index,\n",
    "        y=aggTweets.score,\n",
    "        color=aggTweets['containsKeywords'],\n",
    "        title=f'Average Happiness Score for {eventName}',\n",
    "        labels = {'date':'Date','score':'Avg. Happiness Score', 'containsKeywords': 'Contains Keywords'}\n",
    "    )\n",
    "\n",
    "    return plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performTtest(event, offset:int = 14, tweetsdf:pd.DataFrame =  tweetsdf, positiveEventDates:dict = positiveEventDates):\n",
    "    dateOffset = pd.DateOffset(days=offset)\n",
    "\n",
    "    # Group 1 = pre\n",
    "    # Group 2 = post\n",
    "    group1 = tweetsdf[(tweetsdf['date'] >= (positiveEventDates[event] - dateOffset)) & (tweetsdf['date'] < positiveEventDates[event])]['score']\n",
    "    group2 = tweetsdf[(tweetsdf['date'] <= (positiveEventDates[event] + dateOffset)) & (tweetsdf['date'] > positiveEventDates[event])]['score']\n",
    "\n",
    "    # Check for normality assumption using Shapiro-Wilk test\n",
    "    stat1, p1 = ss.shapiro(group1)\n",
    "    stat2, p2 = ss.shapiro(group2)\n",
    "    alpha = 0.05\n",
    "\n",
    "    if p1 > alpha and p2 > alpha:\n",
    "        print('Both samples are normally distributed.')\n",
    "    else:\n",
    "        print('At least one sample is not normally distributed. However, sample size is large enough to ignore.')\n",
    "\n",
    "    # Check for equal variance assumption using Levene's test\n",
    "    stat, p = ss.levene(group1, group2)\n",
    "    if p > alpha:\n",
    "        var = True\n",
    "        print('Variances are equal.')\n",
    "    else:\n",
    "        var = False\n",
    "        print('Variances are not equal.')\n",
    "\n",
    "    # Perform t-test or welsch t-test assuming \n",
    "    t, p_final = ss.ttest_ind(group1, group2, equal_var=True)\n",
    "    if p_final > alpha:\n",
    "        print(f'There is no significant difference between the groups. p = {p_final}. var = {var}')\n",
    "    else:\n",
    "        print(f'There is a significant difference between the groups. p = {p_final}. var = {var}')\n",
    "\n",
    "    return (p_final, (group1.mean(), len(group1)), (group2.mean(), len(group2)))\n",
    "\n",
    "\n",
    "\n",
    "def performWTtest(event, offset:int = 14, tweetsdf:pd.DataFrame =  tweetsdf, positiveEventDates:dict = positiveEventDates):\n",
    "    dateOffset = pd.DateOffset(days=offset)\n",
    "    alpha = 0.05\n",
    "    # Group 1 = pre\n",
    "    # Group 2 = post\n",
    "    group1 = tweetsdf[(tweetsdf['date'] >= (positiveEventDates[event] - dateOffset)) & (tweetsdf['date'] < positiveEventDates[event])]['score']\n",
    "    group2 = tweetsdf[(tweetsdf['date'] <= (positiveEventDates[event] + dateOffset)) & (tweetsdf['date'] > positiveEventDates[event])]['score']\n",
    "    \n",
    "    # Perform t-test \n",
    "    t, p_final = ss.ttest_ind(group1, group2, equal_var=False)\n",
    "    if p_final> alpha:\n",
    "        print(f'There is no significant difference between the groups. p = {p_final}')\n",
    "    else:\n",
    "        print(f'There is a significant difference between the groups. p = {p_final}')\n",
    "\n",
    "    return (p_final, (group1.mean(), len(group1)), (group2.mean(), len(group2)))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Christmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scipy/stats/_morestats.py:1816: UserWarning:\n",
      "\n",
      "p-value may not be accurate for N > 5000.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are not equal.\n",
      "There is a significant difference between the groups. p = 3.9666063778648937e-29. var = False\n",
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are not equal.\n",
      "There is a significant difference between the groups. p = 1.3780060236716214e-10. var = False\n",
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are not equal.\n",
      "There is a significant difference between the groups. p = 3.806059030298258e-09. var = False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sj/h8ss6gyd3v3ch7qgcmgk8sjm0000gn/T/ipykernel_10930/3858810138.py:103: FutureWarning:\n",
      "\n",
      "this method is deprecated in favour of `Styler.to_html()`\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading page (1/2)\n",
      "Rendering (2/2)                                                    \n",
      "Done                                                               \n",
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are not equal.\n",
      "There is a significant difference between the groups. p = 0.0018100748521344236. var = False\n",
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are not equal.\n",
      "There is a significant difference between the groups. p = 0.0004762924819336148. var = False\n",
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are not equal.\n",
      "There is a significant difference between the groups. p = 0.0006012032905345531. var = False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sj/h8ss6gyd3v3ch7qgcmgk8sjm0000gn/T/ipykernel_10930/3858810138.py:168: FutureWarning:\n",
      "\n",
      "this method is deprecated in favour of `Styler.to_html()`\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading page (1/2)\n",
      "Rendering (2/2)                                                    \n",
      "Done                                                               \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining event and keyword\n",
    "event = 'christmas' \n",
    "keyword = 'christmas'\n",
    "dateOffset = pd.DateOffset(days=14)\n",
    "keywords = ['christmas']\n",
    "title = 'Christmas'\n",
    "\n",
    "# Defining where to store plots\n",
    "plotFile = '../plots/christmas'\n",
    "figW = 800\n",
    "figH = 600\n",
    "\n",
    "# Plotting average happiness around 28-day period for all data\n",
    "plotAvgHappiness(event, keywords, title, 14).write_image(f\"{plotFile}/avgHap28day.png\", format=\"png\", width=figW, height=figH)\n",
    "\n",
    "# Graphing keyword freq \n",
    "## Whole dataset\n",
    "keywordCountsDF  = pd.DataFrame({'date': tweetsdf['date'],'bool':tweetsdf['original_tweet'].str.contains('|'.join(keywords) if len(keywords)>1 else keywords[0])}).groupby(pd.Grouper(key='date', freq='D')).sum()\n",
    "\n",
    "# Plotting keyword freq \n",
    "fig = px.line(\n",
    "    data_frame=keywordCountsDF,\n",
    "    x=keywordCountsDF.index,\n",
    "    y=keywordCountsDF['bool'],\n",
    "    labels={'bool': 'Frequency', 'date': 'Date'}\n",
    ")\n",
    "\n",
    "# Customize the x-axis range\n",
    "fig.update_layout(xaxis_range=['2009-03-15', '2010-03-15'])\n",
    "\n",
    "fig.write_image(f\"{plotFile}/freqWhole.png\", format=\"png\", width=figW, height=figH)\n",
    "\n",
    "## Just 28 days\n",
    "filteredKeywordCountDF = keywordCountsDF.loc[(keywordCountsDF.index >= (positiveEventDates[event] - dateOffset)) & (keywordCountsDF.index <= positiveEventDates[event] + dateOffset)]\n",
    "\n",
    "# Plotting keyword freq around date\n",
    "px.line(\n",
    "    data_frame=filteredKeywordCountDF,\n",
    "    x=filteredKeywordCountDF.index,\n",
    "    y=filteredKeywordCountDF['bool'],\n",
    "    labels={'bool': 'Frequency', 'date': 'Date'}\n",
    ").write_image(f\"{plotFile}/freq28Day.png\", format=\"png\", width=figW, height=figH)\n",
    "\n",
    "# Performing Welsch t-Tests on all data\n",
    "## 28-day\n",
    "t28pValue, t28preData, t28postData = performTtest(event, 14)\n",
    "t28diff = t28postData[0] - t28preData[0]\n",
    "\n",
    "## 14-day\n",
    "t14pValue, t14preData, t14postData = performTtest(event, 7)\n",
    "t14diff = t14postData[0] - t14preData[0]\n",
    "\n",
    "## 6-day\n",
    "t6pValue, t6preData, t6postData = performTtest(event, 3)\n",
    "t6diff = t6postData[0] - t6preData[0]\n",
    "\n",
    "# Performing Mann-Whitney u-Tests on all data\n",
    "## 28-day\n",
    "u28pValue, u28preData, u28postData = performWTtest(event, 14)\n",
    "u28diff = u28postData[0] - u28preData[0]\n",
    "\n",
    "## 14-day\n",
    "u14pValue, u14preData, u14postData = performWTtest(event, 7)\n",
    "u14diff = u14postData[0] - u14preData[0]\n",
    "\n",
    "## 6-day\n",
    "u6pValue, u6preData, u6postData = performWTtest(event, 3)\n",
    "u6diff = u6postData[0] - u6preData[0]\n",
    "\n",
    "# Creating table \n",
    "tableData = {\n",
    "    'Time Period': ['28 days', '14 days', '6 days'], \n",
    "    'Pre-Group Avg. Happiness': [t28preData[0], t14preData[0], t6preData[0]],\n",
    "    'Post-Group Avg. Happiness': [t28postData[0], t14postData[0], t6postData[0]],\n",
    "    'Difference in Avg. Happiness': [t28diff, t14diff, t6diff],\n",
    "    'Sample Size Pre-Group': [t28preData[1], t14preData[1], t6preData[1]],\n",
    "    'Sample Size Post-Group': [t28postData[1], t14postData[1], t6postData[1]],\n",
    "    'Welch\\'s t-Test p-value': [t28pValue, t14pValue, t6pValue],\n",
    "    'Common t-Test p-value': [u28pValue, u14pValue, u6pValue],\n",
    "}\n",
    "\n",
    "table = pd.DataFrame(tableData)\n",
    "styledTable = table.style.format({'Welch\\'s t-Test p-value': '{:.2e}', 'Mann-Whitney U test p-value': '{:.2e}'})\n",
    "styledTable = styledTable.set_properties(**{\n",
    "    'text-align': 'center',\n",
    "    'font-size': '14pt',\n",
    "    'font-family': 'Arial, sans-serif',\n",
    "    'border-collapse': 'collapse',\n",
    "    'border': '1px solid #ddd',\n",
    "    'background-color': '#f7f7f7',\n",
    "    'color': '#333',\n",
    "    'padding': '10px',\n",
    "}).set_table_styles([{    'selector': 'th',    'props': [        ('background-color', '#4CAF50'),        ('color', 'white'),        ('border-top', '1px solid #ddd'),        ('border-bottom', '1px solid #ddd'),        ('font-weight', 'bold'),        ('padding', '10px')    ]\n",
    "}, {\n",
    "    'selector': 'td',\n",
    "    'props': [\n",
    "        ('border-top', '1px solid #ddd'),\n",
    "        ('border-bottom', '1px solid #ddd'),\n",
    "        ('padding', '10px')\n",
    "    ]\n",
    "}])\n",
    "\n",
    "html = styledTable.render()\n",
    "\n",
    "# Save HTML as PNG image using imgkit\n",
    "imgkit.from_string(html, f'{plotFile}/{event}AllData.png')\n",
    "\n",
    "# Performing Welsch t-Tests on filtered data\n",
    "filteredTweetsDF = tweetsdf[tweetsdf['original_tweet'].str.contains('|'.join(keywords) if len(keywords)>1 else keywords[0])]\n",
    "## 28-day\n",
    "t28pValue, t28preData, t28postData = performTtest(event, 14, tweetsdf=filteredTweetsDF)\n",
    "t28diff = t28postData[0] - t28preData[0]\n",
    "\n",
    "## 14-day\n",
    "t14pValue, t14preData, t14postData = performTtest(event, 7, tweetsdf=filteredTweetsDF)\n",
    "t14diff = t14postData[0] - t14preData[0]\n",
    "\n",
    "## 6-day\n",
    "t6pValue, t6preData, t6postData = performTtest(event, 3, tweetsdf=filteredTweetsDF)\n",
    "t6diff = t6postData[0] - t6preData[0]\n",
    "\n",
    "# Performing Mann-Whitney u-Tests on all data\n",
    "## 28-day\n",
    "u28pValue, u28preData, u28postData = performWTtest(event, 14, tweetsdf=filteredTweetsDF)\n",
    "u28diff = u28postData[0] - u28preData[0]\n",
    "\n",
    "## 14-day\n",
    "u14pValue, u14preData, u14postData = performWTtest(event, 7, tweetsdf=filteredTweetsDF)\n",
    "u14diff = u14postData[0] - u14preData[0]\n",
    "\n",
    "## 6-day\n",
    "u6pValue, u6preData, u6postData = performWTtest(event, 3, tweetsdf=filteredTweetsDF)\n",
    "u6diff = u6postData[0] - u6preData[0]\n",
    "\n",
    "# Creating table \n",
    "tableData = {\n",
    "    'Time Period': ['28 days', '14 days', '6 days'], \n",
    "    'Pre-Group Avg. Happiness': [t28preData[0], t14preData[0], t6preData[0]],\n",
    "    'Post-Group Avg. Happiness': [t28postData[0], t14postData[0], t6postData[0]],\n",
    "    'Difference in Avg. Happiness': [t28diff, t14diff, t6diff],\n",
    "    'Sample Size Pre-Group': [t28preData[1], t14preData[1], t6preData[1]],\n",
    "    'Sample Size Post-Group': [t28postData[1], t14postData[1], t6postData[1]],\n",
    "    'Welch\\'s t-Test p-value': [t28pValue, t14pValue, t6pValue],\n",
    "    'Common t-Test p-value': [u28pValue, u14pValue, u6pValue],\n",
    "}\n",
    "\n",
    "table = pd.DataFrame(tableData)\n",
    "styledTable = table.style.format({'Welch\\'s t-Test p-value': '{:.2e}', 'Mann-Whitney U test p-value': '{:.2e}'})\n",
    "styledTable = styledTable.set_properties(**{\n",
    "    'text-align': 'center',\n",
    "    'font-size': '14pt',\n",
    "    'font-family': 'Arial, sans-serif',\n",
    "    'border-collapse': 'collapse',\n",
    "    'border': '1px solid #ddd',\n",
    "    'background-color': '#f7f7f7',\n",
    "    'color': '#333',\n",
    "    'padding': '10px',\n",
    "}).set_table_styles([{    'selector': 'th',    'props': [        ('background-color', '#4CAF50'),        ('color', 'white'),        ('border-top', '1px solid #ddd'),        ('border-bottom', '1px solid #ddd'),        ('font-weight', 'bold'),        ('padding', '10px')    ]\n",
    "}, {\n",
    "    'selector': 'td',\n",
    "    'props': [\n",
    "        ('border-top', '1px solid #ddd'),\n",
    "        ('border-bottom', '1px solid #ddd'),\n",
    "        ('padding', '10px')\n",
    "    ]\n",
    "}])\n",
    "\n",
    "html = styledTable.render()\n",
    "# Save HTML as PNG image using imgkit\n",
    "imgkit.from_string(html, f'{plotFile}/{event}FilteredData.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourth of July"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scipy/stats/_morestats.py:1816: UserWarning:\n",
      "\n",
      "p-value may not be accurate for N > 5000.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are equal.\n",
      "There is no significant difference between the groups. p = 1.1242605648619732e-10. var = True\n",
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are equal.\n",
      "There is no significant difference between the groups. p = 0.02554515254606727. var = True\n",
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are equal.\n",
      "There is no significant difference between the groups. p = 0.844521361722606. var = True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sj/h8ss6gyd3v3ch7qgcmgk8sjm0000gn/T/ipykernel_10930/71120936.py:102: FutureWarning:\n",
      "\n",
      "this method is deprecated in favour of `Styler.to_html()`\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading page (1/2)\n",
      "Rendering (2/2)                                                    \n",
      "Done                                                               \n",
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are equal.\n",
      "There is no significant difference between the groups. p = 0.433155570101458. var = True\n",
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are equal.\n",
      "There is no significant difference between the groups. p = 0.22329612437766083. var = True\n",
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are not equal.\n",
      "There is a significant difference between the groups. p = 0.21582041307940997. var = False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sj/h8ss6gyd3v3ch7qgcmgk8sjm0000gn/T/ipykernel_10930/71120936.py:167: FutureWarning:\n",
      "\n",
      "this method is deprecated in favour of `Styler.to_html()`\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading page (1/2)\n",
      "Rendering (2/2)                                                    \n",
      "Done                                                               \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining event and keyword\n",
    "event = 'liberty' \n",
    "dateOffset = pd.DateOffset(days=14)\n",
    "keywords = ['liberty', 'fourth', 'july', 'freedom']\n",
    "title = 'Fourth of July'\n",
    "\n",
    "# Defining where to store plots\n",
    "plotFile = '../plots/fourth'\n",
    "figW = 800\n",
    "figH = 600\n",
    "\n",
    "# Plotting average happiness around 28-day period for all data\n",
    "plotAvgHappiness(event, keywords, title, 14).write_image(f\"{plotFile}/avgHap28day.png\", format=\"png\", width=figW, height=figH)\n",
    "\n",
    "# Graphing keyword freq \n",
    "## Whole dataset\n",
    "keywordCountsDF  = pd.DataFrame({'date': tweetsdf['date'],'bool':tweetsdf['original_tweet'].str.contains('|'.join(keywords) if len(keywords)>1 else keywords[0])}).groupby(pd.Grouper(key='date', freq='D')).sum()\n",
    "\n",
    "# Plotting keyword freq \n",
    "px.line(\n",
    "    data_frame=keywordCountsDF,\n",
    "    x=keywordCountsDF.index,\n",
    "    y=keywordCountsDF['bool'],\n",
    "    labels={'bool': 'Frequency', 'date': 'Date'}\n",
    ").write_image(f\"{plotFile}/freqWhole.png\", format=\"png\", width=figW, height=figH)\n",
    "\n",
    "## Just 28 days\n",
    "filteredKeywordCountDF = keywordCountsDF.loc[(keywordCountsDF.index >= (positiveEventDates[event] - dateOffset)) & (keywordCountsDF.index <= positiveEventDates[event] + dateOffset)]\n",
    "\n",
    "# Plotting keyword freq \n",
    "fig = px.line(\n",
    "    data_frame=keywordCountsDF,\n",
    "    x=keywordCountsDF.index,\n",
    "    y=keywordCountsDF['bool'],\n",
    "    labels={'bool': 'Frequency', 'date': 'Date'}\n",
    ")\n",
    "\n",
    "# Customize the x-axis range\n",
    "fig.update_layout(xaxis_range=['2009-03-15', '2010-03-15'])\n",
    "\n",
    "fig.write_image(f\"{plotFile}/freqWhole.png\", format=\"png\", width=figW, height=figH)\n",
    "\n",
    "# Performing Welsch t-Tests on all data\n",
    "## 28-day\n",
    "t28pValue, t28preData, t28postData = performTtest(event, 14)\n",
    "t28diff = t28postData[0] - t28preData[0]\n",
    "\n",
    "## 14-day\n",
    "t14pValue, t14preData, t14postData = performTtest(event, 7)\n",
    "t14diff = t14postData[0] - t14preData[0]\n",
    "\n",
    "## 6-day\n",
    "t6pValue, t6preData, t6postData = performTtest(event, 3)\n",
    "t6diff = t6postData[0] - t6preData[0]\n",
    "\n",
    "# Performing Mann-Whitney u-Tests on all data\n",
    "## 28-day\n",
    "u28pValue, u28preData, u28postData = performWTtest(event, 14)\n",
    "u28diff = u28postData[0] - u28preData[0]\n",
    "\n",
    "## 14-day\n",
    "u14pValue, u14preData, u14postData = performWTtest(event, 7)\n",
    "u14diff = u14postData[0] - u14preData[0]\n",
    "\n",
    "## 6-day\n",
    "u6pValue, u6preData, u6postData = performWTtest(event, 3)\n",
    "u6diff = u6postData[0] - u6preData[0]\n",
    "\n",
    "# Creating table \n",
    "tableData = {\n",
    "    'Time Period': ['28 days', '14 days', '6 days'], \n",
    "    'Pre-Group Avg. Happiness': [t28preData[0], t14preData[0], t6preData[0]],\n",
    "    'Post-Group Avg. Happiness': [t28postData[0], t14postData[0], t6postData[0]],\n",
    "    'Difference in Avg. Happiness': [t28diff, t14diff, t6diff],\n",
    "    'Sample Size Pre-Group': [t28preData[1], t14preData[1], t6preData[1]],\n",
    "    'Sample Size Post-Group': [t28postData[1], t14postData[1], t6postData[1]],\n",
    "    'Welch\\'s t-Test p-value': [t28pValue, t14pValue, t6pValue],\n",
    "    'Common t-Test p-value': [u28pValue, u14pValue, u6pValue],\n",
    "}\n",
    "\n",
    "table = pd.DataFrame(tableData)\n",
    "styledTable = table.style.format({'Welch\\'s t-Test p-value': '{:.2e}', 'Mann-Whitney U test p-value': '{:.2e}'})\n",
    "styledTable = styledTable.set_properties(**{\n",
    "    'text-align': 'center',\n",
    "    'font-size': '14pt',\n",
    "    'font-family': 'Arial, sans-serif',\n",
    "    'border-collapse': 'collapse',\n",
    "    'border': '1px solid #ddd',\n",
    "    'background-color': '#f7f7f7',\n",
    "    'color': '#333',\n",
    "    'padding': '10px',\n",
    "}).set_table_styles([{    'selector': 'th',    'props': [        ('background-color', '#4CAF50'),        ('color', 'white'),        ('border-top', '1px solid #ddd'),        ('border-bottom', '1px solid #ddd'),        ('font-weight', 'bold'),        ('padding', '10px')    ]\n",
    "}, {\n",
    "    'selector': 'td',\n",
    "    'props': [\n",
    "        ('border-top', '1px solid #ddd'),\n",
    "        ('border-bottom', '1px solid #ddd'),\n",
    "        ('padding', '10px')\n",
    "    ]\n",
    "}])\n",
    "\n",
    "html = styledTable.render()\n",
    "\n",
    "# Save HTML as PNG image using imgkit\n",
    "imgkit.from_string(html, f'{plotFile}/{event}AllData.png')\n",
    "\n",
    "# Performing Welsch t-Tests on filtered data\n",
    "filteredTweetsDF = tweetsdf[tweetsdf['original_tweet'].str.contains('|'.join(keywords) if len(keywords)>1 else keywords[0])]\n",
    "## 28-day\n",
    "t28pValue, t28preData, t28postData = performTtest(event, 14, tweetsdf=filteredTweetsDF)\n",
    "t28diff = t28postData[0] - t28preData[0]\n",
    "\n",
    "## 14-day\n",
    "t14pValue, t14preData, t14postData = performTtest(event, 7, tweetsdf=filteredTweetsDF)\n",
    "t14diff = t14postData[0] - t14preData[0]\n",
    "\n",
    "## 6-day\n",
    "t6pValue, t6preData, t6postData = performTtest(event, 3, tweetsdf=filteredTweetsDF)\n",
    "t6diff = t6postData[0] - t6preData[0]\n",
    "\n",
    "# Performing Mann-Whitney u-Tests on all data\n",
    "## 28-day\n",
    "u28pValue, u28preData, u28postData = performWTtest(event, 14, tweetsdf=filteredTweetsDF)\n",
    "u28diff = u28postData[0] - u28preData[0]\n",
    "\n",
    "## 14-day\n",
    "u14pValue, u14preData, u14postData = performWTtest(event, 7, tweetsdf=filteredTweetsDF)\n",
    "u14diff = u14postData[0] - u14preData[0]\n",
    "\n",
    "## 6-day\n",
    "u6pValue, u6preData, u6postData = performWTtest(event, 3, tweetsdf=filteredTweetsDF)\n",
    "u6diff = u6postData[0] - u6preData[0]\n",
    "\n",
    "# Creating table \n",
    "tableData = {\n",
    "    'Time Period': ['28 days', '14 days', '6 days'], \n",
    "    'Pre-Group Avg. Happiness': [t28preData[0], t14preData[0], t6preData[0]],\n",
    "    'Post-Group Avg. Happiness': [t28postData[0], t14postData[0], t6postData[0]],\n",
    "    'Difference in Avg. Happiness': [t28diff, t14diff, t6diff],\n",
    "    'Sample Size Pre-Group': [t28preData[1], t14preData[1], t6preData[1]],\n",
    "    'Sample Size Post-Group': [t28postData[1], t14postData[1], t6postData[1]],\n",
    "    'Welch\\'s t-Test p-value': [t28pValue, t14pValue, t6pValue],\n",
    "    'Common t-Test p-value': [u28pValue, u14pValue, u6pValue],\n",
    "}\n",
    "\n",
    "table = pd.DataFrame(tableData)\n",
    "styledTable = table.style.format({'Welch\\'s t-Test p-value': '{:.2e}', 'Mann-Whitney U test p-value': '{:.2e}'})\n",
    "styledTable = styledTable.set_properties(**{\n",
    "    'text-align': 'center',\n",
    "    'font-size': '14pt',\n",
    "    'font-family': 'Arial, sans-serif',\n",
    "    'border-collapse': 'collapse',\n",
    "    'border': '1px solid #ddd',\n",
    "    'background-color': '#f7f7f7',\n",
    "    'color': '#333',\n",
    "    'padding': '10px',\n",
    "}).set_table_styles([{    'selector': 'th',    'props': [        ('background-color', '#4CAF50'),        ('color', 'white'),        ('border-top', '1px solid #ddd'),        ('border-bottom', '1px solid #ddd'),        ('font-weight', 'bold'),        ('padding', '10px')    ]\n",
    "}, {\n",
    "    'selector': 'td',\n",
    "    'props': [\n",
    "        ('border-top', '1px solid #ddd'),\n",
    "        ('border-bottom', '1px solid #ddd'),\n",
    "        ('padding', '10px')\n",
    "    ]\n",
    "}])\n",
    "\n",
    "html = styledTable.render()\n",
    "# Save HTML as PNG image using imgkit\n",
    "imgkit.from_string(html, f'{plotFile}/{event}FilteredData.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nasa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scipy/stats/_morestats.py:1816: UserWarning:\n",
      "\n",
      "p-value may not be accurate for N > 5000.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are equal.\n",
      "There is no significant difference between the groups. p = 1.3680076830157677e-47. var = True\n",
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are equal.\n",
      "There is no significant difference between the groups. p = 4.3604547731598424e-10. var = True\n",
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are equal.\n",
      "There is no significant difference between the groups. p = 2.1191245081830973e-08. var = True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sj/h8ss6gyd3v3ch7qgcmgk8sjm0000gn/T/ipykernel_10930/3045755956.py:102: FutureWarning:\n",
      "\n",
      "this method is deprecated in favour of `Styler.to_html()`\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading page (1/2)\n",
      "Rendering (2/2)                                                    \n",
      "Done                                                               \n",
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are equal.\n",
      "There is no significant difference between the groups. p = 0.14969229003583767. var = True\n",
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are not equal.\n",
      "There is a significant difference between the groups. p = 0.7518618150420562. var = False\n",
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are not equal.\n",
      "There is a significant difference between the groups. p = 0.0006072376576150991. var = False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sj/h8ss6gyd3v3ch7qgcmgk8sjm0000gn/T/ipykernel_10930/3045755956.py:167: FutureWarning:\n",
      "\n",
      "this method is deprecated in favour of `Styler.to_html()`\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading page (1/2)\n",
      "Rendering (2/2)                                                    \n",
      "Done                                                               \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining event and keyword\n",
    "event = 'nasa' \n",
    "dateOffset = pd.DateOffset(days=14)\n",
    "keywords = ['nasa', 'NASA', 'space', 'rocket', 'launch']\n",
    "title = 'Nasa Space Launch'\n",
    "\n",
    "# Defining where to store plots\n",
    "plotFile = '../plots/nasa'\n",
    "figW = 800\n",
    "figH = 600\n",
    "\n",
    "# Plotting average happiness around 28-day period for all data\n",
    "plotAvgHappiness(event, keywords, title, 14).write_image(f\"{plotFile}/avgHap28day.png\", format=\"png\", width=figW, height=figH)\n",
    "\n",
    "# Graphing keyword freq \n",
    "## Whole dataset\n",
    "keywordCountsDF  = pd.DataFrame({'date': tweetsdf['date'],'bool':tweetsdf['original_tweet'].str.contains('|'.join(keywords) if len(keywords)>1 else keywords[0])}).groupby(pd.Grouper(key='date', freq='D')).sum()\n",
    "\n",
    "# Plotting keyword freq \n",
    "fig = px.line(\n",
    "    data_frame=keywordCountsDF,\n",
    "    x=keywordCountsDF.index,\n",
    "    y=keywordCountsDF['bool'],\n",
    "    labels={'bool': 'Frequency', 'date': 'Date'}\n",
    ")\n",
    "\n",
    "# Customize the x-axis range\n",
    "fig.update_layout(xaxis_range=['2009-03-15', '2010-03-15'])\n",
    "\n",
    "fig.write_image(f\"{plotFile}/freqWhole.png\", format=\"png\", width=figW, height=figH)\n",
    "\n",
    "## Just 28 days\n",
    "filteredKeywordCountDF = keywordCountsDF.loc[(keywordCountsDF.index >= (positiveEventDates[event] - dateOffset)) & (keywordCountsDF.index <= positiveEventDates[event] + dateOffset)]\n",
    "\n",
    "# Plotting keyword freq around date\n",
    "px.line(\n",
    "    data_frame=filteredKeywordCountDF,\n",
    "    x=filteredKeywordCountDF.index,\n",
    "    y=filteredKeywordCountDF['bool'],\n",
    "    labels={'bool': 'Frequency', 'date': 'Date'}\n",
    ").write_image(f\"{plotFile}/freq28Day.png\", format=\"png\", width=figW, height=figH)\n",
    "\n",
    "# Performing Welsch t-Tests on all data\n",
    "## 28-day\n",
    "t28pValue, t28preData, t28postData = performTtest(event, 14)\n",
    "t28diff = t28postData[0] - t28preData[0]\n",
    "\n",
    "## 14-day\n",
    "t14pValue, t14preData, t14postData = performTtest(event, 7)\n",
    "t14diff = t14postData[0] - t14preData[0]\n",
    "\n",
    "## 6-day\n",
    "t6pValue, t6preData, t6postData = performTtest(event, 3)\n",
    "t6diff = t6postData[0] - t6preData[0]\n",
    "\n",
    "# Performing Mann-Whitney u-Tests on all data\n",
    "## 28-day\n",
    "u28pValue, u28preData, u28postData = performWTtest(event, 14)\n",
    "u28diff = u28postData[0] - u28preData[0]\n",
    "\n",
    "## 14-day\n",
    "u14pValue, u14preData, u14postData = performWTtest(event, 7)\n",
    "u14diff = u14postData[0] - u14preData[0]\n",
    "\n",
    "## 6-day\n",
    "u6pValue, u6preData, u6postData = performWTtest(event, 3)\n",
    "u6diff = u6postData[0] - u6preData[0]\n",
    "\n",
    "# Creating table \n",
    "tableData = {\n",
    "    'Time Period': ['28 days', '14 days', '6 days'], \n",
    "    'Pre-Group Avg. Happiness': [t28preData[0], t14preData[0], t6preData[0]],\n",
    "    'Post-Group Avg. Happiness': [t28postData[0], t14postData[0], t6postData[0]],\n",
    "    'Difference in Avg. Happiness': [t28diff, t14diff, t6diff],\n",
    "    'Sample Size Pre-Group': [t28preData[1], t14preData[1], t6preData[1]],\n",
    "    'Sample Size Post-Group': [t28postData[1], t14postData[1], t6postData[1]],\n",
    "    'Welch\\'s t-Test p-value': [t28pValue, t14pValue, t6pValue],\n",
    "    'Common t-Test p-value': [u28pValue, u14pValue, u6pValue],\n",
    "}\n",
    "\n",
    "table = pd.DataFrame(tableData)\n",
    "styledTable = table.style.format({'Welch\\'s t-Test p-value': '{:.2e}', 'Mann-Whitney U test p-value': '{:.2e}'})\n",
    "styledTable = styledTable.set_properties(**{\n",
    "    'text-align': 'center',\n",
    "    'font-size': '14pt',\n",
    "    'font-family': 'Arial, sans-serif',\n",
    "    'border-collapse': 'collapse',\n",
    "    'border': '1px solid #ddd',\n",
    "    'background-color': '#f7f7f7',\n",
    "    'color': '#333',\n",
    "    'padding': '10px',\n",
    "}).set_table_styles([{    'selector': 'th',    'props': [        ('background-color', '#4CAF50'),        ('color', 'white'),        ('border-top', '1px solid #ddd'),        ('border-bottom', '1px solid #ddd'),        ('font-weight', 'bold'),        ('padding', '10px')    ]\n",
    "}, {\n",
    "    'selector': 'td',\n",
    "    'props': [\n",
    "        ('border-top', '1px solid #ddd'),\n",
    "        ('border-bottom', '1px solid #ddd'),\n",
    "        ('padding', '10px')\n",
    "    ]\n",
    "}])\n",
    "\n",
    "html = styledTable.render()\n",
    "\n",
    "# Save HTML as PNG image using imgkit\n",
    "imgkit.from_string(html, f'{plotFile}/{event}AllData.png')\n",
    "\n",
    "# Performing Welsch t-Tests on filtered data\n",
    "filteredTweetsDF = tweetsdf[tweetsdf['original_tweet'].str.contains('|'.join(keywords) if len(keywords)>1 else keywords[0])]\n",
    "## 28-day\n",
    "t28pValue, t28preData, t28postData = performTtest(event, 14, tweetsdf=filteredTweetsDF)\n",
    "t28diff = t28postData[0] - t28preData[0]\n",
    "\n",
    "## 14-day\n",
    "t14pValue, t14preData, t14postData = performTtest(event, 7, tweetsdf=filteredTweetsDF)\n",
    "t14diff = t14postData[0] - t14preData[0]\n",
    "\n",
    "## 6-day\n",
    "t6pValue, t6preData, t6postData = performTtest(event, 3, tweetsdf=filteredTweetsDF)\n",
    "t6diff = t6postData[0] - t6preData[0]\n",
    "\n",
    "# Performing Mann-Whitney u-Tests on all data\n",
    "## 28-day\n",
    "u28pValue, u28preData, u28postData = performWTtest(event, 14, tweetsdf=filteredTweetsDF)\n",
    "u28diff = u28postData[0] - u28preData[0]\n",
    "\n",
    "## 14-day\n",
    "u14pValue, u14preData, u14postData = performWTtest(event, 7, tweetsdf=filteredTweetsDF)\n",
    "u14diff = u14postData[0] - u14preData[0]\n",
    "\n",
    "## 6-day\n",
    "u6pValue, u6preData, u6postData = performWTtest(event, 3, tweetsdf=filteredTweetsDF)\n",
    "u6diff = u6postData[0] - u6preData[0]\n",
    "\n",
    "# Creating table \n",
    "tableData = {\n",
    "    'Time Period': ['28 days', '14 days', '6 days'], \n",
    "    'Pre-Group Avg. Happiness': [t28preData[0], t14preData[0], t6preData[0]],\n",
    "    'Post-Group Avg. Happiness': [t28postData[0], t14postData[0], t6postData[0]],\n",
    "    'Difference in Avg. Happiness': [t28diff, t14diff, t6diff],\n",
    "    'Sample Size Pre-Group': [t28preData[1], t14preData[1], t6preData[1]],\n",
    "    'Sample Size Post-Group': [t28postData[1], t14postData[1], t6postData[1]],\n",
    "    'Welch\\'s t-Test p-value': [t28pValue, t14pValue, t6pValue],\n",
    "    'Common t-Test p-value': [u28pValue, u14pValue, u6pValue],\n",
    "}\n",
    "\n",
    "table = pd.DataFrame(tableData)\n",
    "styledTable = table.style.format({'Welch\\'s t-Test p-value': '{:.2e}', 'Mann-Whitney U test p-value': '{:.2e}'})\n",
    "styledTable = styledTable.set_properties(**{\n",
    "    'text-align': 'center',\n",
    "    'font-size': '14pt',\n",
    "    'font-family': 'Arial, sans-serif',\n",
    "    'border-collapse': 'collapse',\n",
    "    'border': '1px solid #ddd',\n",
    "    'background-color': '#f7f7f7',\n",
    "    'color': '#333',\n",
    "    'padding': '10px',\n",
    "}).set_table_styles([{    'selector': 'th',    'props': [        ('background-color', '#4CAF50'),        ('color', 'white'),        ('border-top', '1px solid #ddd'),        ('border-bottom', '1px solid #ddd'),        ('font-weight', 'bold'),        ('padding', '10px')    ]\n",
    "}, {\n",
    "    'selector': 'td',\n",
    "    'props': [\n",
    "        ('border-top', '1px solid #ddd'),\n",
    "        ('border-bottom', '1px solid #ddd'),\n",
    "        ('padding', '10px')\n",
    "    ]\n",
    "}])\n",
    "\n",
    "html = styledTable.render()\n",
    "# Save HTML as PNG image using imgkit\n",
    "imgkit.from_string(html, f'{plotFile}/{event}FilteredData.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Olympics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/scipy/stats/_morestats.py:1816: UserWarning:\n",
      "\n",
      "p-value may not be accurate for N > 5000.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are not equal.\n",
      "There is a significant difference between the groups. p = 4.8564334302349805e-05. var = False\n",
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are equal.\n",
      "There is no significant difference between the groups. p = 0.01802254201682625. var = True\n",
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are not equal.\n",
      "There is a significant difference between the groups. p = 1.4578752666810718e-26. var = False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sj/h8ss6gyd3v3ch7qgcmgk8sjm0000gn/T/ipykernel_10930/1471782210.py:102: FutureWarning:\n",
      "\n",
      "this method is deprecated in favour of `Styler.to_html()`\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading page (1/2)\n",
      "Rendering (2/2)                                                    \n",
      "Done                                                               \n",
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are not equal.\n",
      "There is a significant difference between the groups. p = 2.5512598307645826e-06. var = False\n",
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are equal.\n",
      "There is no significant difference between the groups. p = 7.609213312855402e-06. var = True\n",
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are equal.\n",
      "There is no significant difference between the groups. p = 1.3049245455095034e-05. var = True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sj/h8ss6gyd3v3ch7qgcmgk8sjm0000gn/T/ipykernel_10930/1471782210.py:167: FutureWarning:\n",
      "\n",
      "this method is deprecated in favour of `Styler.to_html()`\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading page (1/2)\n",
      "Rendering (2/2)                                                    \n",
      "Done                                                               \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining event and keyword\n",
    "event = 'olympics' \n",
    "dateOffset = pd.DateOffset(days=14)\n",
    "keywords = ['olympics', 'winter', 'sports']\n",
    "title = 'Winter Olympics'\n",
    "\n",
    "# Defining where to store plots\n",
    "plotFile = '../plots/olympics'\n",
    "figW = 800\n",
    "figH = 600\n",
    "\n",
    "# Plotting average happiness around 28-day period for all data\n",
    "plotAvgHappiness(event, keywords, title, 14).write_image(f\"{plotFile}/avgHap28day.png\", format=\"png\", width=figW, height=figH)\n",
    "\n",
    "# Graphing keyword freq \n",
    "## Whole dataset\n",
    "keywordCountsDF  = pd.DataFrame({'date': tweetsdf['date'],'bool':tweetsdf['original_tweet'].str.contains('|'.join(keywords) if len(keywords)>1 else keywords[0])}).groupby(pd.Grouper(key='date', freq='D')).sum()\n",
    "\n",
    "# Plotting keyword freq \n",
    "px.line(\n",
    "    data_frame=keywordCountsDF,\n",
    "    x=keywordCountsDF.index,\n",
    "    y=keywordCountsDF['bool'],\n",
    "    labels={'bool': 'Frequency', 'date': 'Date'}\n",
    ").write_image(f\"{plotFile}/freqWhole.png\", format=\"png\", width=figW, height=figH)\n",
    "\n",
    "## Just 28 days\n",
    "filteredKeywordCountDF = keywordCountsDF.loc[(keywordCountsDF.index >= (positiveEventDates[event] - dateOffset)) & (keywordCountsDF.index <= positiveEventDates[event] + dateOffset)]\n",
    "\n",
    "# Plotting keyword freq \n",
    "fig = px.line(\n",
    "    data_frame=keywordCountsDF,\n",
    "    x=keywordCountsDF.index,\n",
    "    y=keywordCountsDF['bool'],\n",
    "    labels={'bool': 'Frequency', 'date': 'Date'}\n",
    ")\n",
    "\n",
    "# Customize the x-axis range\n",
    "fig.update_layout(xaxis_range=['2009-03-15', '2010-03-15'])\n",
    "\n",
    "fig.write_image(f\"{plotFile}/freqWhole.png\", format=\"png\", width=figW, height=figH)\n",
    "\n",
    "# Performing Welsch t-Tests on all data\n",
    "## 28-day\n",
    "t28pValue, t28preData, t28postData = performTtest(event, 14)\n",
    "t28diff = t28postData[0] - t28preData[0]\n",
    "\n",
    "## 14-day\n",
    "t14pValue, t14preData, t14postData = performTtest(event, 7)\n",
    "t14diff = t14postData[0] - t14preData[0]\n",
    "\n",
    "## 6-day\n",
    "t6pValue, t6preData, t6postData = performTtest(event, 3)\n",
    "t6diff = t6postData[0] - t6preData[0]\n",
    "\n",
    "# Performing Mann-Whitney u-Tests on all data\n",
    "## 28-day\n",
    "u28pValue, u28preData, u28postData = performWTtest(event, 14)\n",
    "u28diff = u28postData[0] - u28preData[0]\n",
    "\n",
    "## 14-day\n",
    "u14pValue, u14preData, u14postData = performWTtest(event, 7)\n",
    "u14diff = u14postData[0] - u14preData[0]\n",
    "\n",
    "## 6-day\n",
    "u6pValue, u6preData, u6postData = performWTtest(event, 3)\n",
    "u6diff = u6postData[0] - u6preData[0]\n",
    "\n",
    "# Creating table \n",
    "tableData = {\n",
    "    'Time Period': ['28 days', '14 days', '6 days'], \n",
    "    'Pre-Group Avg. Happiness': [t28preData[0], t14preData[0], t6preData[0]],\n",
    "    'Post-Group Avg. Happiness': [t28postData[0], t14postData[0], t6postData[0]],\n",
    "    'Difference in Avg. Happiness': [t28diff, t14diff, t6diff],\n",
    "    'Sample Size Pre-Group': [t28preData[1], t14preData[1], t6preData[1]],\n",
    "    'Sample Size Post-Group': [t28postData[1], t14postData[1], t6postData[1]],\n",
    "    'Welch\\'s t-Test p-value': [t28pValue, t14pValue, t6pValue],\n",
    "    'Common t-Test p-value': [u28pValue, u14pValue, u6pValue],\n",
    "}\n",
    "\n",
    "table = pd.DataFrame(tableData)\n",
    "styledTable = table.style.format({'Welch\\'s t-Test p-value': '{:.2e}', 'Mann-Whitney U test p-value': '{:.2e}'})\n",
    "styledTable = styledTable.set_properties(**{\n",
    "    'text-align': 'center',\n",
    "    'font-size': '14pt',\n",
    "    'font-family': 'Arial, sans-serif',\n",
    "    'border-collapse': 'collapse',\n",
    "    'border': '1px solid #ddd',\n",
    "    'background-color': '#f7f7f7',\n",
    "    'color': '#333',\n",
    "    'padding': '10px',\n",
    "}).set_table_styles([{    'selector': 'th',    'props': [        ('background-color', '#4CAF50'),        ('color', 'white'),        ('border-top', '1px solid #ddd'),        ('border-bottom', '1px solid #ddd'),        ('font-weight', 'bold'),        ('padding', '10px')    ]\n",
    "}, {\n",
    "    'selector': 'td',\n",
    "    'props': [\n",
    "        ('border-top', '1px solid #ddd'),\n",
    "        ('border-bottom', '1px solid #ddd'),\n",
    "        ('padding', '10px')\n",
    "    ]\n",
    "}])\n",
    "\n",
    "html = styledTable.render()\n",
    "\n",
    "# Save HTML as PNG image using imgkit\n",
    "imgkit.from_string(html, f'{plotFile}/{event}AllData.png')\n",
    "\n",
    "# Performing Welsch t-Tests on filtered data\n",
    "filteredTweetsDF = tweetsdf[tweetsdf['original_tweet'].str.contains('|'.join(keywords) if len(keywords)>1 else keywords[0])]\n",
    "## 28-day\n",
    "t28pValue, t28preData, t28postData = performTtest(event, 14, tweetsdf=filteredTweetsDF)\n",
    "t28diff = t28postData[0] - t28preData[0]\n",
    "\n",
    "## 14-day\n",
    "t14pValue, t14preData, t14postData = performTtest(event, 7, tweetsdf=filteredTweetsDF)\n",
    "t14diff = t14postData[0] - t14preData[0]\n",
    "\n",
    "## 6-day\n",
    "t6pValue, t6preData, t6postData = performTtest(event, 3, tweetsdf=filteredTweetsDF)\n",
    "t6diff = t6postData[0] - t6preData[0]\n",
    "\n",
    "# Performing Mann-Whitney u-Tests on all data\n",
    "## 28-day\n",
    "u28pValue, u28preData, u28postData = performWTtest(event, 14, tweetsdf=filteredTweetsDF)\n",
    "u28diff = u28postData[0] - u28preData[0]\n",
    "\n",
    "## 14-day\n",
    "u14pValue, u14preData, u14postData = performWTtest(event, 7, tweetsdf=filteredTweetsDF)\n",
    "u14diff = u14postData[0] - u14preData[0]\n",
    "\n",
    "## 6-day\n",
    "u6pValue, u6preData, u6postData = performWTtest(event, 3, tweetsdf=filteredTweetsDF)\n",
    "u6diff = u6postData[0] - u6preData[0]\n",
    "\n",
    "# Creating table \n",
    "tableData = {\n",
    "    'Time Period': ['28 days', '14 days', '6 days'], \n",
    "    'Pre-Group Avg. Happiness': [t28preData[0], t14preData[0], t6preData[0]],\n",
    "    'Post-Group Avg. Happiness': [t28postData[0], t14postData[0], t6postData[0]],\n",
    "    'Difference in Avg. Happiness': [t28diff, t14diff, t6diff],\n",
    "    'Sample Size Pre-Group': [t28preData[1], t14preData[1], t6preData[1]],\n",
    "    'Sample Size Post-Group': [t28postData[1], t14postData[1], t6postData[1]],\n",
    "    'Welch\\'s t-Test p-value': [t28pValue, t14pValue, t6pValue],\n",
    "    'Common t-Test p-value': [u28pValue, u14pValue, u6pValue],\n",
    "}\n",
    "\n",
    "table = pd.DataFrame(tableData)\n",
    "styledTable = table.style.format({'Welch\\'s t-Test p-value': '{:.2e}', 'Mann-Whitney U test p-value': '{:.2e}'})\n",
    "styledTable = styledTable.set_properties(**{\n",
    "    'text-align': 'center',\n",
    "    'font-size': '14pt',\n",
    "    'font-family': 'Arial, sans-serif',\n",
    "    'border-collapse': 'collapse',\n",
    "    'border': '1px solid #ddd',\n",
    "    'background-color': '#f7f7f7',\n",
    "    'color': '#333',\n",
    "    'padding': '10px',\n",
    "}).set_table_styles([{    'selector': 'th',    'props': [        ('background-color', '#4CAF50'),        ('color', 'white'),        ('border-top', '1px solid #ddd'),        ('border-bottom', '1px solid #ddd'),        ('font-weight', 'bold'),        ('padding', '10px')    ]\n",
    "}, {\n",
    "    'selector': 'td',\n",
    "    'props': [\n",
    "        ('border-top', '1px solid #ddd'),\n",
    "        ('border-bottom', '1px solid #ddd'),\n",
    "        ('padding', '10px')\n",
    "    ]\n",
    "}])\n",
    "\n",
    "html = styledTable.render()\n",
    "# Save HTML as PNG image using imgkit\n",
    "imgkit.from_string(html, f'{plotFile}/{event}FilteredData.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
