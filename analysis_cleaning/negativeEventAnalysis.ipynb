{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daad6fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import scipy.stats as ss\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import imgkit\n",
    "\n",
    "tweetsdf = pd.read_csv('/Users/leemingi/Downloads/finalScores.csv').dropna(subset=['score'])\n",
    "tweetsdf = tweetsdf.iloc[:,2:]\n",
    "tweetsdf.dropna(subset=['hashtags'])\n",
    "# Converting date field to datetime object\n",
    "tweetsdf['date'] = pd.to_datetime(tweetsdf['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8d48fa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dates/Starts of positive events\n",
    "negativeEventDates = {\n",
    "    'flood': pd.Timestamp('2009-09-18'),\n",
    "    'winter-storm': pd.Timestamp('2009-12-19'),\n",
    "    'appomattrox': pd.Timestamp('2010-01-19'),\n",
    "    'fort-hood': pd.Timestamp('2009-11-05')\n",
    "}\n",
    "\n",
    "def plotAvgHappiness(event, keywords, eventName, offset:int = 14, tweetsdf:pd.DataFrame =  tweetsdf, negativeEventDates:dict = negativeEventDates):\n",
    "    dateOffset = pd.DateOffset(days=offset)\n",
    "    # Filtering for tweets that are within two weeks of event\n",
    "    filteredTweets = tweetsdf[(tweetsdf['date'] >= (negativeEventDates[event] - dateOffset)) & (tweetsdf['date'] <= (negativeEventDates[event] + dateOffset))]\n",
    "    newDF = filteredTweets.copy()\n",
    "    newDF.loc[:,'containsKeywords'] = newDF['original_tweet'].str.contains('|'.join(keywords) if len(keywords) > 1 else keywords[0])\n",
    "    newDF.loc[:, 'all'] = 1  # Add a constant column\n",
    "\n",
    "    aggTweets = newDF.groupby(['containsKeywords', pd.Grouper(key='date', freq='D')]).mean(numeric_only=True)\n",
    "    aggTweets = aggTweets.reset_index().set_index('date')\n",
    "\n",
    "    allTweets = newDF.groupby(pd.Grouper(key='date', freq='D')).mean(numeric_only=True)\n",
    "    allTweets['containsKeywords'] = 'All'  # Add a label for the new line\n",
    "\n",
    "    # Combine the DataFrames and sort by date\n",
    "    aggTweets = pd.concat([aggTweets, allTweets]).sort_index()\n",
    "\n",
    "    # Plotting distribution of tweet scores around date\n",
    "    plot = px.line(\n",
    "        data_frame=aggTweets,\n",
    "        x=aggTweets.index,\n",
    "        y=aggTweets.score,\n",
    "        color=aggTweets['containsKeywords'],\n",
    "        title=f'Average Happiness Score for {eventName}',\n",
    "        labels = {'date':'Date','score':'Avg. Happiness Score', 'containsKeywords': 'Contains Keywords'}\n",
    "    )\n",
    "    plot.add_vline(x=negativeEventDates[event])\n",
    "\n",
    "\n",
    "    return plot\n",
    "\n",
    "def plotAvgHappinessGeo(event, keywords, eventName, location, offset:int = 14, tweetsdf:pd.DataFrame =  tweetsdf, negativeEventDates:dict = negativeEventDates):\n",
    "    dateOffset = pd.DateOffset(days=offset)\n",
    "    # Filtering for tweets that are within two weeks of event\n",
    "    filteredTweets = tweetsdf[(tweetsdf['date'] >= (negativeEventDates[event] - dateOffset)) & (tweetsdf['date'] <= (negativeEventDates[event] + dateOffset))]\n",
    "    filteredTweets = filteredTweets[(filteredTweets['latitude'] >= location[0])\n",
    "                            & (filteredTweets['latitude'] <= location[1])\n",
    "                            & (filteredTweets['longitude'] <= location[2])\n",
    "                            & (filteredTweets['longitude'] >= location[3])]\n",
    "\n",
    "    newDF = filteredTweets.copy()\n",
    "    newDF.loc[:,'containsKeywords'] = newDF['original_tweet'].str.contains('|'.join(keywords) if len(keywords) > 1 else keywords[0])\n",
    "    newDF.loc[:, 'all'] = 1  # Add a constant column\n",
    "\n",
    "    aggTweets = newDF.groupby(['containsKeywords', pd.Grouper(key='date', freq='D')]).mean(numeric_only=True)\n",
    "    aggTweets = aggTweets.reset_index().set_index('date')\n",
    "\n",
    "    allTweets = newDF.groupby(pd.Grouper(key='date', freq='D')).mean(numeric_only=True)\n",
    "    allTweets['containsKeywords'] = 'All'  # Add a label for the new line\n",
    "\n",
    "    # Combine the DataFrames and sort by date\n",
    "    aggTweets = pd.concat([aggTweets, allTweets]).sort_index()\n",
    "\n",
    "    # Plotting distribution of tweet scores around date\n",
    "    plot = px.line(\n",
    "        data_frame=aggTweets,\n",
    "        x=aggTweets.index,\n",
    "        y=aggTweets.score,\n",
    "        color=aggTweets['containsKeywords'],\n",
    "        title=f'Average Happiness Score for {eventName} in {location[4]}',\n",
    "        labels = {'date':'Date','score':'Avg. Happiness Score', 'containsKeywords': 'Contains Keywords'}\n",
    "    )\n",
    "    plot.add_vline(x=negativeEventDates[event])\n",
    "\n",
    "\n",
    "    return plot\n",
    "\n",
    "\n",
    "\n",
    "def performTtest(event, offset:int = 14, tweetsdf:pd.DataFrame =  tweetsdf, negativeEventDates:dict = negativeEventDates):\n",
    "    dateOffset = pd.DateOffset(days=offset)\n",
    "\n",
    "    # Group 1 = pre\n",
    "    # Group 2 = post\n",
    "    group1 = tweetsdf[(tweetsdf['date'] >= (negativeEventDates[event] - dateOffset)) & (tweetsdf['date'] < negativeEventDates[event])]['score']\n",
    "    group2 = tweetsdf[(tweetsdf['date'] <= (negativeEventDates[event] + dateOffset)) & (tweetsdf['date'] > negativeEventDates[event])]['score']\n",
    "\n",
    "    # Check for normality assumption using Shapiro-Wilk test\n",
    "    stat1, p1 = ss.shapiro(group1)\n",
    "    stat2, p2 = ss.shapiro(group2)\n",
    "    alpha = 0.05\n",
    "\n",
    "    if p1 > alpha and p2 > alpha:\n",
    "        print('Both samples are normally distributed.')\n",
    "    else:\n",
    "        print('At least one sample is not normally distributed. However, sample size is large enough to ignore.')\n",
    "\n",
    "    # Check for equal variance assumption using Levene's test\n",
    "    stat, p = ss.levene(group1, group2)\n",
    "    if p > alpha:\n",
    "        var = True\n",
    "        print('Variances are equal.')\n",
    "    else:\n",
    "        var = False\n",
    "        print('Variances are not equal.')\n",
    "\n",
    "    # Perform t-test or welsch t-test assuming \n",
    "    t, p_final = ss.ttest_ind(group1, group2, equal_var=False)\n",
    "    if p > alpha:\n",
    "        print(f'There is no significant difference between the groups. p = {p_final}. var = {var}')\n",
    "    else:\n",
    "        print(f'There is a significant difference between the groups. p = {p_final}. var = {var}')\n",
    "\n",
    "    return (p_final, (group1.mean(), len(group1)), (group2.mean(), len(group2)))\n",
    "\n",
    "\n",
    "\n",
    "def performUtest(event, offset:int = 14, tweetsdf:pd.DataFrame =  tweetsdf, negativeEventDates:dict = negativeEventDates):\n",
    "    dateOffset = pd.DateOffset(days=offset)\n",
    "\n",
    "    # Group 1 = pre\n",
    "    # Group 2 = post\n",
    "    group1 = tweetsdf[(tweetsdf['date'] >= (negativeEventDates[event] - dateOffset)) & (tweetsdf['date'] < negativeEventDates[event])]['score']\n",
    "    group2 = tweetsdf[(tweetsdf['date'] <= (negativeEventDates[event] + dateOffset)) & (tweetsdf['date'] > negativeEventDates[event])]['score']\n",
    "\n",
    "    # Perform Mann-Whitney U test\n",
    "    statistic, p_final = ss.mannwhitneyu(group1, group2)\n",
    "\n",
    "    return (p_final, (group1.mean(), len(group1)), (group2.mean(), len(group2)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12826653",
   "metadata": {},
   "source": [
    "# 2009 September Flood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5c01a428",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leemingi/opt/anaconda3/lib/python3.9/site-packages/scipy/stats/_morestats.py:1800: UserWarning:\n",
      "\n",
      "p-value may not be accurate for N > 5000.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are not equal.\n",
      "There is a significant difference between the groups. p = 0.4364986242278558. var = False\n",
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are not equal.\n",
      "There is a significant difference between the groups. p = 0.316726412839658. var = False\n",
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are not equal.\n",
      "There is a significant difference between the groups. p = 0.025287423648294508. var = False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rv/qhv_6w4n707gq2vr6xwbmj9w0000gn/T/ipykernel_17698/515771725.py:103: FutureWarning:\n",
      "\n",
      "this method is deprecated in favour of `Styler.to_html()`\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading page (1/2)\n",
      "Rendering (2/2)                                                    \n",
      "Done                                                               \n",
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are not equal.\n",
      "There is a significant difference between the groups. p = 0.012726834591608895. var = False\n",
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are equal.\n",
      "There is no significant difference between the groups. p = 0.09376361250339224. var = True\n",
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are equal.\n",
      "There is no significant difference between the groups. p = 0.25405611145124685. var = True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rv/qhv_6w4n707gq2vr6xwbmj9w0000gn/T/ipykernel_17698/515771725.py:168: FutureWarning:\n",
      "\n",
      "this method is deprecated in favour of `Styler.to_html()`\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading page (1/2)\n",
      "[>                                                           ] 0%\r",
      "[======>                                                     ] 10%\r",
      "[==============================>                             ] 50%\r",
      "[============================================================] 100%\r",
      "Rendering (2/2)                                                    \n",
      "[>                                                           ] 0%\r",
      "[===============>                                            ] 25%\r",
      "[============================================================] 100%\r",
      "Done                                                               \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining event and keyword\n",
    "event = 'flood' \n",
    "keyword = 'flood'\n",
    "dateOffset = pd.DateOffset(days=14)\n",
    "keywords = ['flood']\n",
    "title = 'flood'\n",
    "\n",
    "# South East US latitudes and longitudes\n",
    "location = [30.5, 35.5, -78.5, -92.5, 'South East US']\n",
    "\n",
    "# Defining where to store plots\n",
    "plotFile = '../plots/flood'\n",
    "figW = 800\n",
    "figH = 600\n",
    "\n",
    "# Plotting average happiness around 28-day period for all data\n",
    "plotAvgHappiness(event, keywords, title, 14).write_image(f\"{plotFile}/avgHap28day.png\", format=\"png\", width=figW, height=figH)\n",
    "plotAvgHappinessGeo(event, keywords, title, location, 14).write_image(f\"{plotFile}/avgHap28daybyLocation.png\", format=\"png\", width=figW, height=figH)\n",
    "\n",
    "\n",
    "# Graphing keyword freq \n",
    "## Whole dataset\n",
    "keywordCountsDF  = pd.DataFrame({'date': tweetsdf['date'],'bool':tweetsdf['original_tweet'].str.contains('|'.join(keywords) if len(keywords)>1 else keywords[0])}).groupby(pd.Grouper(key='date', freq='D')).sum()\n",
    "\n",
    "# Plotting keyword freq \n",
    "px.line(\n",
    "    data_frame=keywordCountsDF,\n",
    "    x=keywordCountsDF.index,\n",
    "    y=keywordCountsDF['bool'],\n",
    "    labels={'bool': 'Frequency', 'date': 'Date'}\n",
    ").write_image(f\"{plotFile}/freqWhole.png\", format=\"png\", width=figW, height=figH)\n",
    "\n",
    "## Just 28 days\n",
    "filteredKeywordCountDF = keywordCountsDF.loc[(keywordCountsDF.index >= (negativeEventDates[event] - dateOffset)) & (keywordCountsDF.index <= negativeEventDates[event] + dateOffset)]\n",
    "\n",
    "# Plotting keyword freq around date\n",
    "px.line(\n",
    "    data_frame=filteredKeywordCountDF,\n",
    "    x=filteredKeywordCountDF.index,\n",
    "    y=filteredKeywordCountDF['bool'],\n",
    "    labels={'bool': 'Frequency', 'date': 'Date'}\n",
    ").write_image(f\"{plotFile}/freq28Day.png\", format=\"png\", width=figW, height=figH)\n",
    "\n",
    "# Performing Welsch t-Tests on all data\n",
    "## 28-day\n",
    "t28pValue, t28preData, t28postData = performTtest(event, 14)\n",
    "t28diff = t28postData[0] - t28preData[0]\n",
    "\n",
    "## 14-day\n",
    "t14pValue, t14preData, t14postData = performTtest(event, 7)\n",
    "t14diff = t14postData[0] - t14preData[0]\n",
    "\n",
    "## 6-day\n",
    "t6pValue, t6preData, t6postData = performTtest(event, 3)\n",
    "t6diff = t6postData[0] - t6preData[0]\n",
    "\n",
    "# Performing Mann-Whitney u-Tests on all data\n",
    "## 28-day\n",
    "u28pValue, u28preData, u28postData = performUtest(event, 14)\n",
    "u28diff = u28postData[0] - u28preData[0]\n",
    "\n",
    "## 14-day\n",
    "u14pValue, u14preData, u14postData = performUtest(event, 7)\n",
    "u14diff = u14postData[0] - u14preData[0]\n",
    "\n",
    "## 6-day\n",
    "u6pValue, u6preData, u6postData = performUtest(event, 3)\n",
    "u6diff = u6postData[0] - u6preData[0]\n",
    "\n",
    "# Creating table \n",
    "tableData = {\n",
    "    'Time Period': ['28 days', '14 days', '6 days'], \n",
    "    'Pre-Group Avg. Happiness': [t28preData[0], t14preData[0], t6preData[0]],\n",
    "    'Post-Group Avg. Happiness': [t28postData[0], t14postData[0], t6postData[0]],\n",
    "    'Difference in Avg. Happiness': [t28diff, t14diff, t6diff],\n",
    "    'Sample Size Pre-Group': [t28preData[1], t14preData[1], t6preData[1]],\n",
    "    'Sample Size Post-Group': [t28postData[1], t14postData[1], t6postData[1]],\n",
    "    'Welch\\'s t-Test p-value': [t28pValue, t14pValue, t6pValue],\n",
    "    'Mann-Whitney U test p-value': [u28pValue, u14pValue, u6pValue],\n",
    "}\n",
    "\n",
    "table = pd.DataFrame(tableData)\n",
    "styledTable = table.style.format({'Welch\\'s t-Test p-value': '{:.2e}', 'Mann-Whitney U test p-value': '{:.2e}'})\n",
    "styledTable = styledTable.set_properties(**{\n",
    "    'text-align': 'center',\n",
    "    'font-size': '14pt',\n",
    "    'font-family': 'Arial, sans-serif',\n",
    "    'border-collapse': 'collapse',\n",
    "    'border': '1px solid #ddd',\n",
    "    'background-color': '#f7f7f7',\n",
    "    'color': '#333',\n",
    "    'padding': '10px',\n",
    "}).set_table_styles([{    'selector': 'th',    'props': [        ('background-color', '#4CAF50'),        ('color', 'white'),        ('border-top', '1px solid #ddd'),        ('border-bottom', '1px solid #ddd'),        ('font-weight', 'bold'),        ('padding', '10px')    ]\n",
    "}, {\n",
    "    'selector': 'td',\n",
    "    'props': [\n",
    "        ('border-top', '1px solid #ddd'),\n",
    "        ('border-bottom', '1px solid #ddd'),\n",
    "        ('padding', '10px')\n",
    "    ]\n",
    "}])\n",
    "\n",
    "html = styledTable.render()\n",
    "\n",
    "# Save HTML as PNG image using imgkit\n",
    "imgkit.from_string(html, f'{plotFile}/{event}AllData.png')\n",
    "\n",
    "# Performing Welsch t-Tests on filtered data\n",
    "filteredTweetsDF = tweetsdf[tweetsdf['original_tweet'].str.contains('|'.join(keywords) if len(keywords)>1 else keywords[0])]\n",
    "## 28-day\n",
    "t28pValue, t28preData, t28postData = performTtest(event, 14, tweetsdf=filteredTweetsDF)\n",
    "t28diff = t28postData[0] - t28preData[0]\n",
    "\n",
    "## 14-day\n",
    "t14pValue, t14preData, t14postData = performTtest(event, 7, tweetsdf=filteredTweetsDF)\n",
    "t14diff = t14postData[0] - t14preData[0]\n",
    "\n",
    "## 6-day\n",
    "t6pValue, t6preData, t6postData = performTtest(event, 3, tweetsdf=filteredTweetsDF)\n",
    "t6diff = t6postData[0] - t6preData[0]\n",
    "\n",
    "# Performing Mann-Whitney u-Tests on all data\n",
    "## 28-day\n",
    "u28pValue, u28preData, u28postData = performUtest(event, 14, tweetsdf=filteredTweetsDF)\n",
    "u28diff = u28postData[0] - u28preData[0]\n",
    "\n",
    "## 14-day\n",
    "u14pValue, u14preData, u14postData = performUtest(event, 7, tweetsdf=filteredTweetsDF)\n",
    "u14diff = u14postData[0] - u14preData[0]\n",
    "\n",
    "## 6-day\n",
    "u6pValue, u6preData, u6postData = performUtest(event, 3, tweetsdf=filteredTweetsDF)\n",
    "u6diff = u6postData[0] - u6preData[0]\n",
    "\n",
    "# Creating table \n",
    "tableData = {\n",
    "    'Time Period': ['28 days', '14 days', '6 days'], \n",
    "    'Pre-Group Avg. Happiness': [t28preData[0], t14preData[0], t6preData[0]],\n",
    "    'Post-Group Avg. Happiness': [t28postData[0], t14postData[0], t6postData[0]],\n",
    "    'Difference in Avg. Happiness': [t28diff, t14diff, t6diff],\n",
    "    'Sample Size Pre-Group': [t28preData[1], t14preData[1], t6preData[1]],\n",
    "    'Sample Size Post-Group': [t28postData[1], t14postData[1], t6postData[1]],\n",
    "    'Welch\\'s t-Test p-value': [t28pValue, t14pValue, t6pValue],\n",
    "    'Mann-Whitney U test p-value': [u28pValue, u14pValue, u6pValue],\n",
    "}\n",
    "\n",
    "table = pd.DataFrame(tableData)\n",
    "styledTable = table.style.format({'Welch\\'s t-Test p-value': '{:.2e}', 'Mann-Whitney U test p-value': '{:.2e}'})\n",
    "styledTable = styledTable.set_properties(**{\n",
    "    'text-align': 'center',\n",
    "    'font-size': '14pt',\n",
    "    'font-family': 'Arial, sans-serif',\n",
    "    'border-collapse': 'collapse',\n",
    "    'border': '1px solid #ddd',\n",
    "    'background-color': '#f7f7f7',\n",
    "    'color': '#333',\n",
    "    'padding': '10px',\n",
    "}).set_table_styles([{    'selector': 'th',    'props': [        ('background-color', '#4CAF50'),        ('color', 'white'),        ('border-top', '1px solid #ddd'),        ('border-bottom', '1px solid #ddd'),        ('font-weight', 'bold'),        ('padding', '10px')    ]\n",
    "}, {\n",
    "    'selector': 'td',\n",
    "    'props': [\n",
    "        ('border-top', '1px solid #ddd'),\n",
    "        ('border-bottom', '1px solid #ddd'),\n",
    "        ('padding', '10px')\n",
    "    ]\n",
    "}])\n",
    "\n",
    "html = styledTable.render()\n",
    "# Save HTML as PNG image using imgkit\n",
    "imgkit.from_string(html, f'{plotFile}/{event}FilteredData.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5810d340",
   "metadata": {},
   "source": [
    "# 2009 December Winter Storm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "15adcb03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leemingi/opt/anaconda3/lib/python3.9/site-packages/scipy/stats/_morestats.py:1800: UserWarning:\n",
      "\n",
      "p-value may not be accurate for N > 5000.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are equal.\n",
      "There is no significant difference between the groups. p = 9.00070923871504e-74. var = True\n",
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are not equal.\n",
      "There is a significant difference between the groups. p = 8.353961399234323e-06. var = False\n",
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are equal.\n",
      "There is no significant difference between the groups. p = 0.054883412532270484. var = True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rv/qhv_6w4n707gq2vr6xwbmj9w0000gn/T/ipykernel_17698/1736569004.py:102: FutureWarning:\n",
      "\n",
      "this method is deprecated in favour of `Styler.to_html()`\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading page (1/2)\n",
      "Rendering (2/2)                                                    \n",
      "Done                                                               \n",
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are equal.\n",
      "There is no significant difference between the groups. p = 0.08410572620200885. var = True\n",
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are equal.\n",
      "There is no significant difference between the groups. p = 0.35519818838663775. var = True\n",
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are equal.\n",
      "There is no significant difference between the groups. p = 0.13053873004570188. var = True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rv/qhv_6w4n707gq2vr6xwbmj9w0000gn/T/ipykernel_17698/1736569004.py:167: FutureWarning:\n",
      "\n",
      "this method is deprecated in favour of `Styler.to_html()`\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading page (1/2)\n",
      "[>                                                           ] 0%\r",
      "[======>                                                     ] 10%\r",
      "[==============================>                             ] 50%\r",
      "[============================================================] 100%\r",
      "Rendering (2/2)                                                    \n",
      "[>                                                           ] 0%\r",
      "[===============>                                            ] 25%\r",
      "[============================================================] 100%\r",
      "Done                                                               \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Defining event and keyword\n",
    "event = 'winter-storm' \n",
    "dateOffset = pd.DateOffset(days=14)\n",
    "keywords = ['storm']\n",
    "title = 'Winter Storm'\n",
    "\n",
    "# South East US\n",
    "location = [38.5, 39.5, -76.5, -77.5, 'Washington DC']\n",
    "\n",
    "\n",
    "# Defining where to store plots\n",
    "plotFile = '../plots/winter-storm'\n",
    "figW = 800\n",
    "figH = 600\n",
    "\n",
    "# Plotting average happiness around 28-day period for all data\n",
    "plotAvgHappiness(event, keywords, title, 14).write_image(f\"{plotFile}/avgHap28day.png\", format=\"png\", width=figW, height=figH)\n",
    "plotAvgHappinessGeo(event, keywords, title, location, 14).write_image(f\"{plotFile}/avgHap28daybyLocation.png\", format=\"png\", width=figW, height=figH)\n",
    "\n",
    "# Graphing keyword freq \n",
    "## Whole dataset\n",
    "keywordCountsDF  = pd.DataFrame({'date': tweetsdf['date'],'bool':tweetsdf['original_tweet'].str.contains('|'.join(keywords) if len(keywords)>1 else keywords[0])}).groupby(pd.Grouper(key='date', freq='D')).sum()\n",
    "\n",
    "# Plotting keyword freq \n",
    "px.line(\n",
    "    data_frame=keywordCountsDF,\n",
    "    x=keywordCountsDF.index,\n",
    "    y=keywordCountsDF['bool'],\n",
    "    labels={'bool': 'Frequency', 'date': 'Date'}\n",
    ").write_image(f\"{plotFile}/freqWhole.png\", format=\"png\", width=figW, height=figH)\n",
    "\n",
    "## Just 28 days\n",
    "filteredKeywordCountDF = keywordCountsDF.loc[(keywordCountsDF.index >= (negativeEventDates[event] - dateOffset)) & (keywordCountsDF.index <= negativeEventDates[event] + dateOffset)]\n",
    "\n",
    "# Plotting keyword freq around date\n",
    "px.line(\n",
    "    data_frame=filteredKeywordCountDF,\n",
    "    x=filteredKeywordCountDF.index,\n",
    "    y=filteredKeywordCountDF['bool'],\n",
    "    labels={'bool': 'Frequency', 'date': 'Date'}\n",
    ").write_image(f\"{plotFile}/freq28Day.png\", format=\"png\", width=figW, height=figH)\n",
    "\n",
    "# Performing Welsch t-Tests on all data\n",
    "## 28-day\n",
    "t28pValue, t28preData, t28postData = performTtest(event, 14)\n",
    "t28diff = t28postData[0] - t28preData[0]\n",
    "\n",
    "## 14-day\n",
    "t14pValue, t14preData, t14postData = performTtest(event, 7)\n",
    "t14diff = t14postData[0] - t14preData[0]\n",
    "\n",
    "## 6-day\n",
    "t6pValue, t6preData, t6postData = performTtest(event, 3)\n",
    "t6diff = t6postData[0] - t6preData[0]\n",
    "\n",
    "# Performing Mann-Whitney u-Tests on all data\n",
    "## 28-day\n",
    "u28pValue, u28preData, u28postData = performUtest(event, 14)\n",
    "u28diff = u28postData[0] - u28preData[0]\n",
    "\n",
    "## 14-day\n",
    "u14pValue, u14preData, u14postData = performUtest(event, 7)\n",
    "u14diff = u14postData[0] - u14preData[0]\n",
    "\n",
    "## 6-day\n",
    "u6pValue, u6preData, u6postData = performUtest(event, 3)\n",
    "u6diff = u6postData[0] - u6preData[0]\n",
    "\n",
    "# Creating table \n",
    "tableData = {\n",
    "    'Time Period': ['28 days', '14 days', '6 days'], \n",
    "    'Pre-Group Avg. Happiness': [t28preData[0], t14preData[0], t6preData[0]],\n",
    "    'Post-Group Avg. Happiness': [t28postData[0], t14postData[0], t6postData[0]],\n",
    "    'Difference in Avg. Happiness': [t28diff, t14diff, t6diff],\n",
    "    'Sample Size Pre-Group': [t28preData[1], t14preData[1], t6preData[1]],\n",
    "    'Sample Size Post-Group': [t28postData[1], t14postData[1], t6postData[1]],\n",
    "    'Welch\\'s t-Test p-value': [t28pValue, t14pValue, t6pValue],\n",
    "    'Mann-Whitney U test p-value': [u28pValue, u14pValue, u6pValue],\n",
    "}\n",
    "\n",
    "table = pd.DataFrame(tableData)\n",
    "styledTable = table.style.format({'Welch\\'s t-Test p-value': '{:.2e}', 'Mann-Whitney U test p-value': '{:.2e}'})\n",
    "styledTable = styledTable.set_properties(**{\n",
    "    'text-align': 'center',\n",
    "    'font-size': '14pt',\n",
    "    'font-family': 'Arial, sans-serif',\n",
    "    'border-collapse': 'collapse',\n",
    "    'border': '1px solid #ddd',\n",
    "    'background-color': '#f7f7f7',\n",
    "    'color': '#333',\n",
    "    'padding': '10px',\n",
    "}).set_table_styles([{    'selector': 'th',    'props': [        ('background-color', '#4CAF50'),        ('color', 'white'),        ('border-top', '1px solid #ddd'),        ('border-bottom', '1px solid #ddd'),        ('font-weight', 'bold'),        ('padding', '10px')    ]\n",
    "}, {\n",
    "    'selector': 'td',\n",
    "    'props': [\n",
    "        ('border-top', '1px solid #ddd'),\n",
    "        ('border-bottom', '1px solid #ddd'),\n",
    "        ('padding', '10px')\n",
    "    ]\n",
    "}])\n",
    "\n",
    "html = styledTable.render()\n",
    "\n",
    "# Save HTML as PNG image using imgkit\n",
    "imgkit.from_string(html, f'{plotFile}/{event}AllData.png')\n",
    "\n",
    "# Performing Welsch t-Tests on filtered data\n",
    "filteredTweetsDF = tweetsdf[tweetsdf['original_tweet'].str.contains('|'.join(keywords) if len(keywords)>1 else keywords[0])]\n",
    "## 28-day\n",
    "t28pValue, t28preData, t28postData = performTtest(event, 14, tweetsdf=filteredTweetsDF)\n",
    "t28diff = t28postData[0] - t28preData[0]\n",
    "\n",
    "## 14-day\n",
    "t14pValue, t14preData, t14postData = performTtest(event, 7, tweetsdf=filteredTweetsDF)\n",
    "t14diff = t14postData[0] - t14preData[0]\n",
    "\n",
    "## 6-day\n",
    "t6pValue, t6preData, t6postData = performTtest(event, 3, tweetsdf=filteredTweetsDF)\n",
    "t6diff = t6postData[0] - t6preData[0]\n",
    "\n",
    "# Performing Mann-Whitney u-Tests on all data\n",
    "## 28-day\n",
    "u28pValue, u28preData, u28postData = performUtest(event, 14, tweetsdf=filteredTweetsDF)\n",
    "u28diff = u28postData[0] - u28preData[0]\n",
    "\n",
    "## 14-day\n",
    "u14pValue, u14preData, u14postData = performUtest(event, 7, tweetsdf=filteredTweetsDF)\n",
    "u14diff = u14postData[0] - u14preData[0]\n",
    "\n",
    "## 6-day\n",
    "u6pValue, u6preData, u6postData = performUtest(event, 3, tweetsdf=filteredTweetsDF)\n",
    "u6diff = u6postData[0] - u6preData[0]\n",
    "\n",
    "# Creating table \n",
    "tableData = {\n",
    "    'Time Period': ['28 days', '14 days', '6 days'], \n",
    "    'Pre-Group Avg. Happiness': [t28preData[0], t14preData[0], t6preData[0]],\n",
    "    'Post-Group Avg. Happiness': [t28postData[0], t14postData[0], t6postData[0]],\n",
    "    'Difference in Avg. Happiness': [t28diff, t14diff, t6diff],\n",
    "    'Sample Size Pre-Group': [t28preData[1], t14preData[1], t6preData[1]],\n",
    "    'Sample Size Post-Group': [t28postData[1], t14postData[1], t6postData[1]],\n",
    "    'Welch\\'s t-Test p-value': [t28pValue, t14pValue, t6pValue],\n",
    "    'Mann-Whitney U test p-value': [u28pValue, u14pValue, u6pValue],\n",
    "}\n",
    "\n",
    "table = pd.DataFrame(tableData)\n",
    "styledTable = table.style.format({'Welch\\'s t-Test p-value': '{:.2e}', 'Mann-Whitney U test p-value': '{:.2e}'})\n",
    "styledTable = styledTable.set_properties(**{\n",
    "    'text-align': 'center',\n",
    "    'font-size': '14pt',\n",
    "    'font-family': 'Arial, sans-serif',\n",
    "    'border-collapse': 'collapse',\n",
    "    'border': '1px solid #ddd',\n",
    "    'background-color': '#f7f7f7',\n",
    "    'color': '#333',\n",
    "    'padding': '10px',\n",
    "}).set_table_styles([{    'selector': 'th',    'props': [        ('background-color', '#4CAF50'),        ('color', 'white'),        ('border-top', '1px solid #ddd'),        ('border-bottom', '1px solid #ddd'),        ('font-weight', 'bold'),        ('padding', '10px')    ]\n",
    "}, {\n",
    "    'selector': 'td',\n",
    "    'props': [\n",
    "        ('border-top', '1px solid #ddd'),\n",
    "        ('border-bottom', '1px solid #ddd'),\n",
    "        ('padding', '10px')\n",
    "    ]\n",
    "}])\n",
    "\n",
    "html = styledTable.render()\n",
    "# Save HTML as PNG image using imgkit\n",
    "imgkit.from_string(html, f'{plotFile}/{event}FilteredData.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "71dc149f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leemingi/opt/anaconda3/lib/python3.9/site-packages/scipy/stats/_morestats.py:1800: UserWarning:\n",
      "\n",
      "p-value may not be accurate for N > 5000.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are not equal.\n",
      "There is a significant difference between the groups. p = 0.006667688598761199. var = False\n",
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are not equal.\n",
      "There is a significant difference between the groups. p = 0.4995133422811191. var = False\n",
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are equal.\n",
      "There is no significant difference between the groups. p = 0.2234390365702976. var = True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rv/qhv_6w4n707gq2vr6xwbmj9w0000gn/T/ipykernel_17698/2502830193.py:102: FutureWarning:\n",
      "\n",
      "this method is deprecated in favour of `Styler.to_html()`\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading page (1/2)\n",
      "Rendering (2/2)                                                    \n",
      "Done                                                               \n",
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are equal.\n",
      "There is no significant difference between the groups. p = 0.516312186682454. var = True\n",
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are equal.\n",
      "There is no significant difference between the groups. p = 0.630730738064629. var = True\n",
      "At least one sample is not normally distributed. However, sample size is large enough to ignore.\n",
      "Variances are equal.\n",
      "There is no significant difference between the groups. p = 0.7939521545801682. var = True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rv/qhv_6w4n707gq2vr6xwbmj9w0000gn/T/ipykernel_17698/2502830193.py:167: FutureWarning:\n",
      "\n",
      "this method is deprecated in favour of `Styler.to_html()`\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading page (1/2)\n",
      "[>                                                           ] 0%\r",
      "[======>                                                     ] 10%\r",
      "[==============================>                             ] 50%\r",
      "[============================================================] 100%\r",
      "Rendering (2/2)                                                    \n",
      "[>                                                           ] 0%\r",
      "[===============>                                            ] 25%\r",
      "[============================================================] 100%\r",
      "Done                                                               \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Defining event and keyword\n",
    "event = 'appomattrox' \n",
    "dateOffset = pd.DateOffset(days=14)\n",
    "keywords = ['shooting', 'gun']\n",
    "title = 'Appomattrox Mass Shooting'\n",
    "\n",
    "# Virginia\n",
    "location = [25, 47, -72, -78, 'Virginia']\n",
    "\n",
    "\n",
    "# Defining where to store plots\n",
    "plotFile = '../plots/appomattrox'\n",
    "figW = 800\n",
    "figH = 600\n",
    "\n",
    "# Plotting average happiness around 28-day period for all data\n",
    "plotAvgHappiness(event, keywords, title, 14).write_image(f\"{plotFile}/avgHap28day.png\", format=\"png\", width=figW, height=figH)\n",
    "plotAvgHappinessGeo(event, keywords, title, location, 14).write_image(f\"{plotFile}/avgHap28daybyLocation.png\", format=\"png\", width=figW, height=figH)\n",
    "\n",
    "# Graphing keyword freq \n",
    "## Whole dataset\n",
    "keywordCountsDF  = pd.DataFrame({'date': tweetsdf['date'],'bool':tweetsdf['original_tweet'].str.contains('|'.join(keywords) if len(keywords)>1 else keywords[0])}).groupby(pd.Grouper(key='date', freq='D')).sum()\n",
    "\n",
    "# Plotting keyword freq \n",
    "px.line(\n",
    "    data_frame=keywordCountsDF,\n",
    "    x=keywordCountsDF.index,\n",
    "    y=keywordCountsDF['bool'],\n",
    "    labels={'bool': 'Frequency', 'date': 'Date'}\n",
    ").write_image(f\"{plotFile}/freqWhole.png\", format=\"png\", width=figW, height=figH)\n",
    "\n",
    "## Just 28 days\n",
    "filteredKeywordCountDF = keywordCountsDF.loc[(keywordCountsDF.index >= (negativeEventDates[event] - dateOffset)) & (keywordCountsDF.index <= negativeEventDates[event] + dateOffset)]\n",
    "\n",
    "# Plotting keyword freq around date\n",
    "px.line(\n",
    "    data_frame=filteredKeywordCountDF,\n",
    "    x=filteredKeywordCountDF.index,\n",
    "    y=filteredKeywordCountDF['bool'],\n",
    "    labels={'bool': 'Frequency', 'date': 'Date'}\n",
    ").write_image(f\"{plotFile}/freq28Day.png\", format=\"png\", width=figW, height=figH)\n",
    "\n",
    "# Performing Welsch t-Tests on all data\n",
    "## 28-day\n",
    "t28pValue, t28preData, t28postData = performTtest(event, 14)\n",
    "t28diff = t28postData[0] - t28preData[0]\n",
    "\n",
    "## 14-day\n",
    "t14pValue, t14preData, t14postData = performTtest(event, 7)\n",
    "t14diff = t14postData[0] - t14preData[0]\n",
    "\n",
    "## 6-day\n",
    "t6pValue, t6preData, t6postData = performTtest(event, 3)\n",
    "t6diff = t6postData[0] - t6preData[0]\n",
    "\n",
    "# Performing Mann-Whitney u-Tests on all data\n",
    "## 28-day\n",
    "u28pValue, u28preData, u28postData = performUtest(event, 14)\n",
    "u28diff = u28postData[0] - u28preData[0]\n",
    "\n",
    "## 14-day\n",
    "u14pValue, u14preData, u14postData = performUtest(event, 7)\n",
    "u14diff = u14postData[0] - u14preData[0]\n",
    "\n",
    "## 6-day\n",
    "u6pValue, u6preData, u6postData = performUtest(event, 3)\n",
    "u6diff = u6postData[0] - u6preData[0]\n",
    "\n",
    "# Creating table \n",
    "tableData = {\n",
    "    'Time Period': ['28 days', '14 days', '6 days'], \n",
    "    'Pre-Group Avg. Happiness': [t28preData[0], t14preData[0], t6preData[0]],\n",
    "    'Post-Group Avg. Happiness': [t28postData[0], t14postData[0], t6postData[0]],\n",
    "    'Difference in Avg. Happiness': [t28diff, t14diff, t6diff],\n",
    "    'Sample Size Pre-Group': [t28preData[1], t14preData[1], t6preData[1]],\n",
    "    'Sample Size Post-Group': [t28postData[1], t14postData[1], t6postData[1]],\n",
    "    'Welch\\'s t-Test p-value': [t28pValue, t14pValue, t6pValue],\n",
    "    'Mann-Whitney U test p-value': [u28pValue, u14pValue, u6pValue],\n",
    "}\n",
    "\n",
    "table = pd.DataFrame(tableData)\n",
    "styledTable = table.style.format({'Welch\\'s t-Test p-value': '{:.2e}', 'Mann-Whitney U test p-value': '{:.2e}'})\n",
    "styledTable = styledTable.set_properties(**{\n",
    "    'text-align': 'center',\n",
    "    'font-size': '14pt',\n",
    "    'font-family': 'Arial, sans-serif',\n",
    "    'border-collapse': 'collapse',\n",
    "    'border': '1px solid #ddd',\n",
    "    'background-color': '#f7f7f7',\n",
    "    'color': '#333',\n",
    "    'padding': '10px',\n",
    "}).set_table_styles([{    'selector': 'th',    'props': [        ('background-color', '#4CAF50'),        ('color', 'white'),        ('border-top', '1px solid #ddd'),        ('border-bottom', '1px solid #ddd'),        ('font-weight', 'bold'),        ('padding', '10px')    ]\n",
    "}, {\n",
    "    'selector': 'td',\n",
    "    'props': [\n",
    "        ('border-top', '1px solid #ddd'),\n",
    "        ('border-bottom', '1px solid #ddd'),\n",
    "        ('padding', '10px')\n",
    "    ]\n",
    "}])\n",
    "\n",
    "html = styledTable.render()\n",
    "\n",
    "# Save HTML as PNG image using imgkit\n",
    "imgkit.from_string(html, f'{plotFile}/{event}AllData.png')\n",
    "\n",
    "# Performing Welsch t-Tests on filtered data\n",
    "filteredTweetsDF = tweetsdf[tweetsdf['original_tweet'].str.contains('|'.join(keywords) if len(keywords)>1 else keywords[0])]\n",
    "## 28-day\n",
    "t28pValue, t28preData, t28postData = performTtest(event, 14, tweetsdf=filteredTweetsDF)\n",
    "t28diff = t28postData[0] - t28preData[0]\n",
    "\n",
    "## 14-day\n",
    "t14pValue, t14preData, t14postData = performTtest(event, 7, tweetsdf=filteredTweetsDF)\n",
    "t14diff = t14postData[0] - t14preData[0]\n",
    "\n",
    "## 6-day\n",
    "t6pValue, t6preData, t6postData = performTtest(event, 3, tweetsdf=filteredTweetsDF)\n",
    "t6diff = t6postData[0] - t6preData[0]\n",
    "\n",
    "# Performing Mann-Whitney u-Tests on all data\n",
    "## 28-day\n",
    "u28pValue, u28preData, u28postData = performUtest(event, 14, tweetsdf=filteredTweetsDF)\n",
    "u28diff = u28postData[0] - u28preData[0]\n",
    "\n",
    "## 14-day\n",
    "u14pValue, u14preData, u14postData = performUtest(event, 7, tweetsdf=filteredTweetsDF)\n",
    "u14diff = u14postData[0] - u14preData[0]\n",
    "\n",
    "## 6-day\n",
    "u6pValue, u6preData, u6postData = performUtest(event, 3, tweetsdf=filteredTweetsDF)\n",
    "u6diff = u6postData[0] - u6preData[0]\n",
    "\n",
    "# Creating table \n",
    "tableData = {\n",
    "    'Time Period': ['28 days', '14 days', '6 days'], \n",
    "    'Pre-Group Avg. Happiness': [t28preData[0], t14preData[0], t6preData[0]],\n",
    "    'Post-Group Avg. Happiness': [t28postData[0], t14postData[0], t6postData[0]],\n",
    "    'Difference in Avg. Happiness': [t28diff, t14diff, t6diff],\n",
    "    'Sample Size Pre-Group': [t28preData[1], t14preData[1], t6preData[1]],\n",
    "    'Sample Size Post-Group': [t28postData[1], t14postData[1], t6postData[1]],\n",
    "    'Welch\\'s t-Test p-value': [t28pValue, t14pValue, t6pValue],\n",
    "    'Mann-Whitney U test p-value': [u28pValue, u14pValue, u6pValue],\n",
    "}\n",
    "\n",
    "table = pd.DataFrame(tableData)\n",
    "styledTable = table.style.format({'Welch\\'s t-Test p-value': '{:.2e}', 'Mann-Whitney U test p-value': '{:.2e}'})\n",
    "styledTable = styledTable.set_properties(**{\n",
    "    'text-align': 'center',\n",
    "    'font-size': '14pt',\n",
    "    'font-family': 'Arial, sans-serif',\n",
    "    'border-collapse': 'collapse',\n",
    "    'border': '1px solid #ddd',\n",
    "    'background-color': '#f7f7f7',\n",
    "    'color': '#333',\n",
    "    'padding': '10px',\n",
    "}).set_table_styles([{    'selector': 'th',    'props': [        ('background-color', '#4CAF50'),        ('color', 'white'),        ('border-top', '1px solid #ddd'),        ('border-bottom', '1px solid #ddd'),        ('font-weight', 'bold'),        ('padding', '10px')    ]\n",
    "}, {\n",
    "    'selector': 'td',\n",
    "    'props': [\n",
    "        ('border-top', '1px solid #ddd'),\n",
    "        ('border-bottom', '1px solid #ddd'),\n",
    "        ('padding', '10px')\n",
    "    ]\n",
    "}])\n",
    "\n",
    "html = styledTable.render()\n",
    "# Save HTML as PNG image using imgkit\n",
    "imgkit.from_string(html, f'{plotFile}/{event}FilteredData.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1c348625",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4261863952.py, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/rv/qhv_6w4n707gq2vr6xwbmj9w0000gn/T/ipykernel_17698/4261863952.py\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    locations = [ 25, 36, -94, -106. 'Texas']\u001b[0m\n\u001b[0m                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Defining event and keyword\n",
    "event = 'fort-hood' \n",
    "dateOffset = pd.DateOffset(days=14)\n",
    "keywords = ['shooting', 'gun']\n",
    "title = 'Fort Hood Mass Shooting'\n",
    "\n",
    "# Texas\n",
    "locations = [ 25, 36, -94, -106. 'Texas']\n",
    "\n",
    "# Defining where to store plots\n",
    "plotFile = '../plots/fort-hood'\n",
    "figW = 800\n",
    "figH = 600\n",
    "\n",
    "# Plotting average happiness around 28-day period for all data\n",
    "plotAvgHappiness(event, keywords, title, 14).write_image(f\"{plotFile}/avgHap28day.png\", format=\"png\", width=figW, height=figH)\n",
    "plotAvgHappinessGeo(event, keywords, title, location, 14).write_image(f\"{plotFile}/avgHap28daybyLocation.png\", format=\"png\", width=figW, height=figH)\n",
    "\n",
    "# Graphing keyword freq \n",
    "## Whole dataset\n",
    "keywordCountsDF  = pd.DataFrame({'date': tweetsdf['date'],'bool':tweetsdf['original_tweet'].str.contains('|'.join(keywords) if len(keywords)>1 else keywords[0])}).groupby(pd.Grouper(key='date', freq='D')).sum()\n",
    "\n",
    "# Plotting keyword freq \n",
    "px.line(\n",
    "    data_frame=keywordCountsDF,\n",
    "    x=keywordCountsDF.index,\n",
    "    y=keywordCountsDF['bool'],\n",
    "    labels={'bool': 'Frequency', 'date': 'Date'}\n",
    ").write_image(f\"{plotFile}/freqWhole.png\", format=\"png\", width=figW, height=figH)\n",
    "\n",
    "## Just 28 days\n",
    "filteredKeywordCountDF = keywordCountsDF.loc[(keywordCountsDF.index >= (negativeEventDates[event] - dateOffset)) & (keywordCountsDF.index <= negativeEventDates[event] + dateOffset)]\n",
    "\n",
    "# Plotting keyword freq around date\n",
    "px.line(\n",
    "    data_frame=filteredKeywordCountDF,\n",
    "    x=filteredKeywordCountDF.index,\n",
    "    y=filteredKeywordCountDF['bool'],\n",
    "    labels={'bool': 'Frequency', 'date': 'Date'}\n",
    ").write_image(f\"{plotFile}/freq28Day.png\", format=\"png\", width=figW, height=figH)\n",
    "\n",
    "# Performing Welsch t-Tests on all data\n",
    "## 28-day\n",
    "t28pValue, t28preData, t28postData = performTtest(event, 14)\n",
    "t28diff = t28postData[0] - t28preData[0]\n",
    "\n",
    "## 14-day\n",
    "t14pValue, t14preData, t14postData = performTtest(event, 7)\n",
    "t14diff = t14postData[0] - t14preData[0]\n",
    "\n",
    "## 6-day\n",
    "t6pValue, t6preData, t6postData = performTtest(event, 3)\n",
    "t6diff = t6postData[0] - t6preData[0]\n",
    "\n",
    "# Performing Mann-Whitney u-Tests on all data\n",
    "## 28-day\n",
    "u28pValue, u28preData, u28postData = performUtest(event, 14)\n",
    "u28diff = u28postData[0] - u28preData[0]\n",
    "\n",
    "## 14-day\n",
    "u14pValue, u14preData, u14postData = performUtest(event, 7)\n",
    "u14diff = u14postData[0] - u14preData[0]\n",
    "\n",
    "## 6-day\n",
    "u6pValue, u6preData, u6postData = performUtest(event, 3)\n",
    "u6diff = u6postData[0] - u6preData[0]\n",
    "\n",
    "# Creating table \n",
    "tableData = {\n",
    "    'Time Period': ['28 days', '14 days', '6 days'], \n",
    "    'Pre-Group Avg. Happiness': [t28preData[0], t14preData[0], t6preData[0]],\n",
    "    'Post-Group Avg. Happiness': [t28postData[0], t14postData[0], t6postData[0]],\n",
    "    'Difference in Avg. Happiness': [t28diff, t14diff, t6diff],\n",
    "    'Sample Size Pre-Group': [t28preData[1], t14preData[1], t6preData[1]],\n",
    "    'Sample Size Post-Group': [t28postData[1], t14postData[1], t6postData[1]],\n",
    "    'Welch\\'s t-Test p-value': [t28pValue, t14pValue, t6pValue],\n",
    "    'Mann-Whitney U test p-value': [u28pValue, u14pValue, u6pValue],\n",
    "}\n",
    "\n",
    "table = pd.DataFrame(tableData)\n",
    "styledTable = table.style.format({'Welch\\'s t-Test p-value': '{:.2e}', 'Mann-Whitney U test p-value': '{:.2e}'})\n",
    "styledTable = styledTable.set_properties(**{\n",
    "    'text-align': 'center',\n",
    "    'font-size': '14pt',\n",
    "    'font-family': 'Arial, sans-serif',\n",
    "    'border-collapse': 'collapse',\n",
    "    'border': '1px solid #ddd',\n",
    "    'background-color': '#f7f7f7',\n",
    "    'color': '#333',\n",
    "    'padding': '10px',\n",
    "}).set_table_styles([{    'selector': 'th',    'props': [        ('background-color', '#4CAF50'),        ('color', 'white'),        ('border-top', '1px solid #ddd'),        ('border-bottom', '1px solid #ddd'),        ('font-weight', 'bold'),        ('padding', '10px')    ]\n",
    "}, {\n",
    "    'selector': 'td',\n",
    "    'props': [\n",
    "        ('border-top', '1px solid #ddd'),\n",
    "        ('border-bottom', '1px solid #ddd'),\n",
    "        ('padding', '10px')\n",
    "    ]\n",
    "}])\n",
    "\n",
    "html = styledTable.render()\n",
    "\n",
    "# Save HTML as PNG image using imgkit\n",
    "imgkit.from_string(html, f'{plotFile}/{event}AllData.png')\n",
    "\n",
    "# Performing Welsch t-Tests on filtered data\n",
    "filteredTweetsDF = tweetsdf[tweetsdf['original_tweet'].str.contains('|'.join(keywords) if len(keywords)>1 else keywords[0])]\n",
    "## 28-day\n",
    "t28pValue, t28preData, t28postData = performTtest(event, 14, tweetsdf=filteredTweetsDF)\n",
    "t28diff = t28postData[0] - t28preData[0]\n",
    "\n",
    "## 14-day\n",
    "t14pValue, t14preData, t14postData = performTtest(event, 7, tweetsdf=filteredTweetsDF)\n",
    "t14diff = t14postData[0] - t14preData[0]\n",
    "\n",
    "## 6-day\n",
    "t6pValue, t6preData, t6postData = performTtest(event, 3, tweetsdf=filteredTweetsDF)\n",
    "t6diff = t6postData[0] - t6preData[0]\n",
    "\n",
    "# Performing Mann-Whitney u-Tests on all data\n",
    "## 28-day\n",
    "u28pValue, u28preData, u28postData = performUtest(event, 14, tweetsdf=filteredTweetsDF)\n",
    "u28diff = u28postData[0] - u28preData[0]\n",
    "\n",
    "## 14-day\n",
    "u14pValue, u14preData, u14postData = performUtest(event, 7, tweetsdf=filteredTweetsDF)\n",
    "u14diff = u14postData[0] - u14preData[0]\n",
    "\n",
    "## 6-day\n",
    "u6pValue, u6preData, u6postData = performUtest(event, 3, tweetsdf=filteredTweetsDF)\n",
    "u6diff = u6postData[0] - u6preData[0]\n",
    "\n",
    "# Creating table \n",
    "tableData = {\n",
    "    'Time Period': ['28 days', '14 days', '6 days'], \n",
    "    'Pre-Group Avg. Happiness': [t28preData[0], t14preData[0], t6preData[0]],\n",
    "    'Post-Group Avg. Happiness': [t28postData[0], t14postData[0], t6postData[0]],\n",
    "    'Difference in Avg. Happiness': [t28diff, t14diff, t6diff],\n",
    "    'Sample Size Pre-Group': [t28preData[1], t14preData[1], t6preData[1]],\n",
    "    'Sample Size Post-Group': [t28postData[1], t14postData[1], t6postData[1]],\n",
    "    'Welch\\'s t-Test p-value': [t28pValue, t14pValue, t6pValue],\n",
    "    'Mann-Whitney U test p-value': [u28pValue, u14pValue, u6pValue],\n",
    "}\n",
    "\n",
    "table = pd.DataFrame(tableData)\n",
    "styledTable = table.style.format({'Welch\\'s t-Test p-value': '{:.2e}', 'Mann-Whitney U test p-value': '{:.2e}'})\n",
    "styledTable = styledTable.set_properties(**{\n",
    "    'text-align': 'center',\n",
    "    'font-size': '14pt',\n",
    "    'font-family': 'Arial, sans-serif',\n",
    "    'border-collapse': 'collapse',\n",
    "    'border': '1px solid #ddd',\n",
    "    'background-color': '#f7f7f7',\n",
    "    'color': '#333',\n",
    "    'padding': '10px',\n",
    "}).set_table_styles([{    'selector': 'th',    'props': [        ('background-color', '#4CAF50'),        ('color', 'white'),        ('border-top', '1px solid #ddd'),        ('border-bottom', '1px solid #ddd'),        ('font-weight', 'bold'),        ('padding', '10px')    ]\n",
    "}, {\n",
    "    'selector': 'td',\n",
    "    'props': [\n",
    "        ('border-top', '1px solid #ddd'),\n",
    "        ('border-bottom', '1px solid #ddd'),\n",
    "        ('padding', '10px')\n",
    "    ]\n",
    "}])\n",
    "\n",
    "html = styledTable.render()\n",
    "# Save HTML as PNG image using imgkit\n",
    "imgkit.from_string(html, f'{plotFile}/{event}FilteredData.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
